{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aYXAQXRv9vgn"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade git+https://github.com/keras-team/keras-cv -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dMTcKKGH9vgn",
    "outputId": "12f98969-478b-48ca-8188-1a836e169f74"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrea/tfenvl/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-03-02 09:44:36.715836: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-02 09:44:36.921253: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-02 09:44:36.921293: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-02 09:44:36.956659: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-02 09:44:37.039188: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-02 09:44:38.195068: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "import keras_cv\n",
    "from keras_cv import bounding_box\n",
    "from keras_cv import visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_ids = [\n",
    "    #\"TV\", \"bed\", \"chair\", \"clock\", \"console\", \"consoleeeeee\", \"door\", \"fan\", \"light\", \"sofa\", \"switchboard\", \"table\"\n",
    "    #\"emptychair\", \"fullchair\"\n",
    "    #\"Chair\",\"Sofa\",\"Table\"\n",
    "    \"Cane\", \"Gatto\"\n",
    "]\n",
    "class_mapping = dict(zip(range(len(class_ids)), class_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8l_FG3lG9vgq",
    "outputId": "78070df1-0b4d-4da5-ceef-fd82e4b05294"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-02 09:44:42.757217: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-02 09:44:42.872786: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-02 09:44:42.872828: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-02 09:44:42.877681: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-02 09:44:42.877771: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-02 09:44:42.877789: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-02 09:44:45.450298: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-02 09:44:45.450357: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-02 09:44:45.450364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-03-02 09:44:45.450394: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-02 09:44:45.450416: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1590 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "/home/andrea/tfenvl/lib/python3.10/site-packages/keras_cv/src/models/backbones/backbone.py:44: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  return id(getattr(self, attr)) not in self._functional_layer_ids\n",
      "/home/andrea/tfenvl/lib/python3.10/site-packages/keras_cv/src/models/backbones/backbone.py:44: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  return id(getattr(self, attr)) not in self._functional_layer_ids\n"
     ]
    }
   ],
   "source": [
    "backbone = keras_cv.models.YOLOV8Backbone.from_preset(\n",
    "    \"yolo_v8_m_backbone_coco\",  # We will use yolov8 small backbone with coco weights\n",
    "    load_weights=True\n",
    ")\n",
    "backbone.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-d0fxOA39vgu"
   },
   "outputs": [],
   "source": [
    "yolo = keras_cv.models.YOLOV8Detector(\n",
    "    num_classes=len(class_mapping),\n",
    "    bounding_box_format=\"xyxy\",\n",
    "    backbone=backbone,\n",
    "    #fpn_depth=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "sY6tk0O9MiAc"
   },
   "outputs": [],
   "source": [
    "yolo.load_weights(\"model-m-bbfreez-animali.h5\")\n",
    "#yolo = keras_cv.models.load(\"model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo.prediction_decoder = keras_cv.layers.NonMaxSuppression(\n",
    "    bounding_box_format=\"xyxy\",\n",
    "    from_logits=False,\n",
    "    iou_threshold=0.1,\n",
    "    confidence_threshold=0.05,\n",
    "    max_detections=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 497
    },
    "id": "fE2zGCtdMZqZ",
    "outputId": "ac8afa4a-c306-414d-97e1-ac85d7976a5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 608ms/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 80\u001b[0m\n\u001b[1;32m     45\u001b[0m     visualization\u001b[38;5;241m.\u001b[39mplot_bounding_box_gallery(\n\u001b[1;32m     46\u001b[0m         orig_image,\n\u001b[1;32m     47\u001b[0m         value_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     56\u001b[0m         class_mapping\u001b[38;5;241m=\u001b[39mclass_mapping,\n\u001b[1;32m     57\u001b[0m     )\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# y_pred[\"boxes\"] = tf.squeeze(y_pred[\"boxes\"], axis=0)\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# visualization.draw_bounding_boxes(\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m#     image,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# visualize_generic(yolo, image_name=\"../test_images/testimage_4.jpg\", bounding_box_format=\"xyxy\")\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# visualize_generic(yolo, image_name=\"../test_images/testimage_5.jpg\", bounding_box_format=\"xyxy\")\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m \u001b[43mvisualize_generic\u001b[49m\u001b[43m(\u001b[49m\u001b[43myolo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../animali/valid/cane-e-gatto-insieme.jpg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounding_box_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mxyxy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m visualize_generic(yolo, image_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../animali/valid/IMG_0206-768x513.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m, bounding_box_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxyxy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# visualize_generic(yolo, image_name=\"../animali/valid/183005673-110464f6-fd3c-42b8-9c38-553f0e46a50d.jpg\", bounding_box_format=\"xyxy\")\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# visualize_generic(yolo, image_name=\"../animali/valid/cani-gatti-litigano-m.jpg\", bounding_box_format=\"xyxy\")\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# visualize_generic(yolo, image_name=\"../animali/valid/dog-2606759_640.jpg\", bounding_box_format=\"xyxy\")\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m#img_0120_jpg.rf.36da0f1b2f59ec13cb70e1b82defd9a0.jpg\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[11], line 22\u001b[0m, in \u001b[0;36mvisualize_generic\u001b[0;34m(model, image_name, bounding_box_format)\u001b[0m\n\u001b[1;32m     19\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(image)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#y_pred = bounding_box.to_ragged(y_pred)\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[43mvisualization\u001b[49m\u001b[38;5;241m.\u001b[39mplot_bounding_box_gallery(\n\u001b[1;32m     23\u001b[0m     image,\n\u001b[1;32m     24\u001b[0m     value_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m),\n\u001b[1;32m     25\u001b[0m     bounding_box_format\u001b[38;5;241m=\u001b[39mbounding_box_format,\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m#y_true={},\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     y_pred\u001b[38;5;241m=\u001b[39my_pred,\n\u001b[1;32m     28\u001b[0m     scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,\n\u001b[1;32m     29\u001b[0m     rows\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     30\u001b[0m     cols\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     31\u001b[0m     show\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     32\u001b[0m     font_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m,\n\u001b[1;32m     33\u001b[0m     class_mapping\u001b[38;5;241m=\u001b[39mclass_mapping,\n\u001b[1;32m     34\u001b[0m )\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(y_pred[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboxes\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][:\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m     37\u001b[0m boxes \u001b[38;5;241m=\u001b[39m y_pred[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboxes\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "Cell \u001b[0;32mIn[11], line 22\u001b[0m, in \u001b[0;36mvisualize_generic\u001b[0;34m(model, image_name, bounding_box_format)\u001b[0m\n\u001b[1;32m     19\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(image)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#y_pred = bounding_box.to_ragged(y_pred)\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[43mvisualization\u001b[49m\u001b[38;5;241m.\u001b[39mplot_bounding_box_gallery(\n\u001b[1;32m     23\u001b[0m     image,\n\u001b[1;32m     24\u001b[0m     value_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m),\n\u001b[1;32m     25\u001b[0m     bounding_box_format\u001b[38;5;241m=\u001b[39mbounding_box_format,\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m#y_true={},\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     y_pred\u001b[38;5;241m=\u001b[39my_pred,\n\u001b[1;32m     28\u001b[0m     scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,\n\u001b[1;32m     29\u001b[0m     rows\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     30\u001b[0m     cols\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     31\u001b[0m     show\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     32\u001b[0m     font_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m,\n\u001b[1;32m     33\u001b[0m     class_mapping\u001b[38;5;241m=\u001b[39mclass_mapping,\n\u001b[1;32m     34\u001b[0m )\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(y_pred[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboxes\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][:\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m     37\u001b[0m boxes \u001b[38;5;241m=\u001b[39m y_pred[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboxes\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/tfenvl/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/tfenvl/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2106\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[1;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def visualize_generic(model, image_name, bounding_box_format):\n",
    "    h = 640\n",
    "    w = 640\n",
    "    #images = load_image(os.path.join(path_images, image_name))\n",
    "    orig_image = tf.io.read_file(image_name)\n",
    "    orig_image = tf.image.decode_jpeg(orig_image, channels=3)\n",
    "    orig_h = orig_image.shape[0]\n",
    "    orig_w = orig_image.shape[1]\n",
    "    rh = orig_h/h\n",
    "    rw = orig_w/w\n",
    "\n",
    "    image = tf.image.resize(orig_image, [h,w])\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.expand_dims(image, axis=0)\n",
    "    \n",
    "    orig_image = tf.cast(orig_image, tf.float32)\n",
    "    orig_image = tf.expand_dims(orig_image, axis=0)\n",
    "\n",
    "    y_pred = model.predict(image)\n",
    "    #y_pred = bounding_box.to_ragged(y_pred)\n",
    "\n",
    "    visualization.plot_bounding_box_gallery(\n",
    "        image,\n",
    "        value_range=(0, 255),\n",
    "        bounding_box_format=bounding_box_format,\n",
    "        #y_true={},\n",
    "        y_pred=y_pred,\n",
    "        scale=4,\n",
    "        rows=1,\n",
    "        cols=1,\n",
    "        show=True,\n",
    "        font_scale=0.7,\n",
    "        class_mapping=class_mapping,\n",
    "    )\n",
    "\n",
    "    print(y_pred[\"boxes\"][0][:2])\n",
    "    boxes = y_pred[\"boxes\"]\n",
    "    for box in boxes[0]:\n",
    "        box[0] = box[0]*rw\n",
    "        box[1] = box[1]*rh\n",
    "        box[2] = box[2]*rw\n",
    "        box[3] = box[3]*rh\n",
    "    print(y_pred[\"boxes\"][0][:2])\n",
    "\n",
    "    visualization.plot_bounding_box_gallery(\n",
    "        orig_image,\n",
    "        value_range=(0, 255),\n",
    "        bounding_box_format=bounding_box_format,\n",
    "        #y_true={},\n",
    "        y_pred=y_pred,\n",
    "        scale=4,\n",
    "        rows=1,\n",
    "        cols=1,\n",
    "        show=True,\n",
    "        font_scale=0.7,\n",
    "        class_mapping=class_mapping,\n",
    "    )\n",
    "    \n",
    "    # y_pred[\"boxes\"] = tf.squeeze(y_pred[\"boxes\"], axis=0)\n",
    "    # visualization.draw_bounding_boxes(\n",
    "    #     image,\n",
    "    #     y_pred,\n",
    "    #     color= \"red\",\n",
    "    #     bounding_box_format=bounding_box_format,\n",
    "    #     class_mapping=class_mapping\n",
    "    # )\n",
    "\n",
    "# visualize_generic(yolo, image_name=\"../dataset1/test/00012_jpg.rf.f54b7ef0968cf6b0f990928d169e1a83.jpg\", bounding_box_format=\"xyxy\")\n",
    "# visualize_generic(yolo, image_name=\"../dataset1/test/00041_jpg.rf.1b685611d13e60bfd19b1ad008eb81c9.jpg\", bounding_box_format=\"xyxy\")\n",
    "# visualize_generic(yolo, image_name=\"../dataset1/test/00059_jpg.rf.f69bbdb4d09580675715e9a203470631.jpg\", bounding_box_format=\"xyxy\")\n",
    "# visualize_generic(yolo, image_name=\"../dataset3/test/Chair-269-_jpg.rf.3a81b0889599ce42bc735ff199f7e536.jpg\", bounding_box_format=\"xyxy\")\n",
    "# visualize_generic(yolo, image_name=\"../dataset3/test/Sofa-359-_jpg.rf.2995061f9eaae4bca7913b736e3e49a1.jpg\", bounding_box_format=\"xyxy\")\n",
    "# visualize_generic(yolo, image_name=\"../dataset3/test/Chairs1-16-_jpg.rf.a4506ce899294f71c7fd534a42534144.jpg\", bounding_box_format=\"xyxy\")\n",
    "# visualize_generic(yolo, image_name=\"../test_images/testimage_1.jpg\", bounding_box_format=\"xyxy\")\n",
    "# visualize_generic(yolo, image_name=\"../test_images/testimage_2.jpg\", bounding_box_format=\"xyxy\")\n",
    "# visualize_generic(yolo, image_name=\"../test_images/testimage_3.jpg\", bounding_box_format=\"xyxy\")\n",
    "# visualize_generic(yolo, image_name=\"../test_images/testimage_4.jpg\", bounding_box_format=\"xyxy\")\n",
    "# visualize_generic(yolo, image_name=\"../test_images/testimage_5.jpg\", bounding_box_format=\"xyxy\")\n",
    "\n",
    "visualize_generic(yolo, image_name=\"../animali/valid/cane-e-gatto-insieme.jpg\", bounding_box_format=\"xyxy\")\n",
    "visualize_generic(yolo, image_name=\"../animali/valid/IMG_0206-768x513.jpg\", bounding_box_format=\"xyxy\")\n",
    "# visualize_generic(yolo, image_name=\"../animali/valid/183005673-110464f6-fd3c-42b8-9c38-553f0e46a50d.jpg\", bounding_box_format=\"xyxy\")\n",
    "# visualize_generic(yolo, image_name=\"../animali/valid/cani-gatti-litigano-m.jpg\", bounding_box_format=\"xyxy\")\n",
    "# visualize_generic(yolo, image_name=\"../animali/valid/dog-2606759_640.jpg\", bounding_box_format=\"xyxy\")\n",
    "\n",
    "#img_0120_jpg.rf.36da0f1b2f59ec13cb70e1b82defd9a0.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "23e4a255f1664c699d2d6cf00253559c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b618213856a34ec3830ad0b48a5a0028",
      "placeholder": "​",
      "style": "IPY_MODEL_8c4cd4fca7d349d5b5d0eb212d5d84f2",
      "value": " 4660/4660 [00:03&lt;00:00, 1138.91it/s]"
     }
    },
    "2b949297991243388c2bbd0a04760f41": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a1c6cbfd5c614a68ba9a3bb1f5efc5f7",
       "IPY_MODEL_611f30558a3d4278bb6cdeb52c98cff5",
       "IPY_MODEL_23e4a255f1664c699d2d6cf00253559c"
      ],
      "layout": "IPY_MODEL_6fc913a8f1604a639b5a45437af4718c"
     }
    },
    "5dc5446c9611411ca61b12b715253919": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "611f30558a3d4278bb6cdeb52c98cff5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5dc5446c9611411ca61b12b715253919",
      "max": 4660,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_66722e0666bf4bfa96238cdec21491f6",
      "value": 4660
     }
    },
    "66722e0666bf4bfa96238cdec21491f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "66b3cacb326448829fc378be51cbeebe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6fc913a8f1604a639b5a45437af4718c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8c4cd4fca7d349d5b5d0eb212d5d84f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a1c6cbfd5c614a68ba9a3bb1f5efc5f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e3c791bfcf6c453d85dae4f359b74f83",
      "placeholder": "​",
      "style": "IPY_MODEL_66b3cacb326448829fc378be51cbeebe",
      "value": "100%"
     }
    },
    "b618213856a34ec3830ad0b48a5a0028": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e3c791bfcf6c453d85dae4f359b74f83": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
