{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade git+https://github.com/keras-team/keras-cv -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8b4mPR0JE1Zv",
    "outputId": "6e8612ba-28fa-445d-e5e4-a80b6449e0c0"
   },
   "outputs": [],
   "source": [
    "#!wget https://universe.roboflow.com/ds/J2gwc4lbUt?key=EDrj9yWOXp -O indoor_object_detection.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WNwwp1WkJSBm",
    "outputId": "b5fd8bff-0eef-416e-e251-3372b18c623c"
   },
   "outputs": [],
   "source": [
    "#!unzip \"indoor_object_detection.zip\" -d \"dataset2/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aYXAQXRv9vgn"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dMTcKKGH9vgn",
    "outputId": "12f98969-478b-48ca-8188-1a836e169f74"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 17:51:29.422699: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-06 17:51:30.316140: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-06 17:51:30.316210: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-06 17:51:30.492217: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-06 17:51:30.841885: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-06 17:51:32.681937: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import keras_cv\n",
    "from keras_cv import bounding_box\n",
    "from keras_cv import visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ggo8MEBW9vgo"
   },
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "6HHbmkEh9vgo"
   },
   "outputs": [],
   "source": [
    "SPLIT_RATIO = 0.2\n",
    "BATCH_SIZE = 2\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCH = 50\n",
    "GLOBAL_CLIPNORM = 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "i3XXhcIN9vgo"
   },
   "outputs": [],
   "source": [
    "class_ids = [\n",
    "    #\"TV\", \"bed\", \"chair\", \"clock\", \"console\", \"consoleeeeee\", \"door\", \"fan\", \"light\", \"sofa\", \"switchboard\", \"table\"\n",
    "    \"emptychair\", \"fullchair\"\n",
    "]\n",
    "class_mapping = dict(zip(range(len(class_ids)), class_ids))\n",
    "\n",
    "# Path to images and annotations\n",
    "path_images = \"../dataset2/train/\"\n",
    "path_annot = \"../dataset2/train/\"\n",
    "\n",
    "# Get all XML file paths in path_annot and sort them\n",
    "xml_files = sorted(\n",
    "    [\n",
    "        os.path.join(path_annot, file_name)\n",
    "        for file_name in os.listdir(path_annot)\n",
    "        if file_name.endswith(\".xml\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Get all JPEG image file paths in path_images and sort them\n",
    "jpg_files = sorted(\n",
    "    [\n",
    "        os.path.join(path_images, file_name)\n",
    "        for file_name in os.listdir(path_images)\n",
    "        if file_name.endswith(\".jpg\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "2b949297991243388c2bbd0a04760f41",
      "a1c6cbfd5c614a68ba9a3bb1f5efc5f7",
      "611f30558a3d4278bb6cdeb52c98cff5",
      "23e4a255f1664c699d2d6cf00253559c",
      "6fc913a8f1604a639b5a45437af4718c",
      "e3c791bfcf6c453d85dae4f359b74f83",
      "66b3cacb326448829fc378be51cbeebe",
      "5dc5446c9611411ca61b12b715253919",
      "66722e0666bf4bfa96238cdec21491f6",
      "b618213856a34ec3830ad0b48a5a0028",
      "8c4cd4fca7d349d5b5d0eb212d5d84f2"
     ]
    },
    "id": "4ix2L_Gw9vgo",
    "outputId": "f93fe7ce-c63f-435a-8d18-47bfcff1898f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "628763d1f67c40e8bb36909702eee837",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4780 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def parse_annotation(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    image_name = root.find(\"filename\").text\n",
    "    image_path = os.path.join(path_images, image_name)\n",
    "\n",
    "    boxes = []\n",
    "    classes = []\n",
    "    for obj in root.iter(\"object\"):\n",
    "        cls = obj.find(\"name\").text\n",
    "        classes.append(cls)\n",
    "\n",
    "        bbox = obj.find(\"bndbox\")\n",
    "        xmin = float(bbox.find(\"xmin\").text)\n",
    "        ymin = float(bbox.find(\"ymin\").text)\n",
    "        xmax = float(bbox.find(\"xmax\").text)\n",
    "        ymax = float(bbox.find(\"ymax\").text)\n",
    "        boxes.append([xmin, ymin, xmax, ymax])\n",
    "\n",
    "    class_ids = [\n",
    "        list(class_mapping.keys())[list(class_mapping.values()).index(cls)]\n",
    "        for cls in classes\n",
    "    ]\n",
    "    return image_path, boxes, class_ids\n",
    "\n",
    "\n",
    "image_paths = []\n",
    "bbox = []\n",
    "classes = []\n",
    "for xml_file in tqdm(xml_files):\n",
    "    image_path, boxes, class_ids = parse_annotation(xml_file)\n",
    "    image_paths.append(image_path)\n",
    "    bbox.append(boxes)\n",
    "    classes.append(class_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "wQoyFPH09vgp"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 17:54:09.531110: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-06 17:54:09.869970: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-06 17:54:09.870026: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-06 17:54:09.890195: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-06 17:54:09.890290: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-06 17:54:09.890309: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-06 17:58:46.915251: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-06 17:58:46.918450: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-06 17:58:46.918506: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-02-06 17:58:46.920223: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-06 17:58:46.924851: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1590 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "bbox = tf.ragged.constant(bbox)\n",
    "classes = tf.ragged.constant(classes)\n",
    "image_paths = tf.ragged.constant(image_paths)\n",
    "\n",
    "data = tf.data.Dataset.from_tensor_slices((image_paths, classes, bbox))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "KiKEdWTd9vgp"
   },
   "outputs": [],
   "source": [
    "# Determine the number of validation samples\n",
    "num_val = int(len(xml_files) * SPLIT_RATIO)\n",
    "\n",
    "# Split the dataset into train and validation sets\n",
    "val_data = data.take(num_val)\n",
    "train_data = data.skip(num_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YI_j-84Jop52",
    "outputId": "1b103efb-b50f-494e-d510-0a05f311f651"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4780\n",
      "956\n",
      "tf.Tensor(3824, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print(len(image_paths))\n",
    "print(num_val)\n",
    "print(train_data.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "LH5RhWEN9vgp"
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_image(image_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    return image\n",
    "\n",
    "\n",
    "def load_dataset(image_path, classes, bbox):\n",
    "    # Read Image\n",
    "    image = load_image(image_path)\n",
    "    bounding_boxes = {\n",
    "        \"classes\": tf.cast(classes, dtype=tf.float32),\n",
    "        \"boxes\": bbox,\n",
    "    }\n",
    "    return {\"images\": tf.cast(image, tf.float32), \"bounding_boxes\": bounding_boxes}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "bTAJ1Fvg9vgp"
   },
   "outputs": [],
   "source": [
    "augmenter = keras.Sequential(\n",
    "    layers=[\n",
    "        keras_cv.layers.RandomFlip(mode=\"horizontal\", bounding_box_format=\"xyxy\"),\n",
    "        keras_cv.layers.RandomShear(\n",
    "            x_factor=0.2, y_factor=0.2, bounding_box_format=\"xyxy\"\n",
    "        ),\n",
    "        keras_cv.layers.JitteredResize(\n",
    "            target_size=(640, 640), scale_factor=(0.75, 1.3), bounding_box_format=\"xyxy\"\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X53NKYSG9vgp"
   },
   "source": [
    "## Creating Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "CVEHbwRD9vgq"
   },
   "outputs": [],
   "source": [
    "train_ds = train_data.map(load_dataset, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_ds = train_ds.shuffle(BATCH_SIZE * 4)\n",
    "train_ds = train_ds.ragged_batch(BATCH_SIZE, drop_remainder=True)\n",
    "train_ds = train_ds.map(augmenter, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lUvSvgyO9vgq"
   },
   "source": [
    "## Creating Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "32ncwija9vgq"
   },
   "outputs": [],
   "source": [
    "resizing = keras_cv.layers.JitteredResize(\n",
    "    target_size=(640, 640),\n",
    "    scale_factor=(0.75, 1.3),\n",
    "    bounding_box_format=\"xyxy\",\n",
    ")\n",
    "\n",
    "val_ds = val_data.map(load_dataset, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.shuffle(BATCH_SIZE * 4)\n",
    "val_ds = val_ds.ragged_batch(BATCH_SIZE, drop_remainder=True)\n",
    "val_ds = val_ds.map(resizing, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "haPcKl4t9vgq"
   },
   "outputs": [],
   "source": [
    "def dict_to_tuple(inputs):\n",
    "    return inputs[\"images\"], inputs[\"bounding_boxes\"]\n",
    "\n",
    "\n",
    "train_ds = train_ds.map(dict_to_tuple, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_ds = val_ds.map(dict_to_tuple, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0yZtYWl99vgq"
   },
   "source": [
    "## Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8l_FG3lG9vgq",
    "outputId": "78070df1-0b4d-4da5-ceef-fd82e4b05294"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrea/.local/lib/python3.10/site-packages/keras_cv/models/backbones/backbone.py:44: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  return id(getattr(self, attr)) not in self._functional_layer_ids\n",
      "/home/andrea/.local/lib/python3.10/site-packages/keras_cv/models/backbones/backbone.py:44: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  return id(getattr(self, attr)) not in self._functional_layer_ids\n"
     ]
    }
   ],
   "source": [
    "backbone = keras_cv.models.YOLOV8Backbone.from_preset(\n",
    "    \"yolo_v8_s_backbone_coco\",  # We will use yolov8 small backbone with coco weights\n",
    "    trainable = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "-d0fxOA39vgu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"yolov8_detector\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, None, None, 3)]      0         []                            \n",
      "                                                                                                  \n",
      " model (Functional)          {'P3': (None, None, None,    5089760   ['input_2[0][0]']             \n",
      "                             128),                                                                \n",
      "                              'P4': (None, None, None,                                            \n",
      "                             256),                                                                \n",
      "                              'P5': (None, None, None,                                            \n",
      "                             512)}                                                                \n",
      "                                                                                                  \n",
      " tf.repeat (TFOpLambda)      (None, None, None, 512)      0         ['model[0][2]']               \n",
      "                                                                                                  \n",
      " tf.repeat_1 (TFOpLambda)    (None, None, None, 512)      0         ['tf.repeat[0][0]']           \n",
      "                                                                                                  \n",
      " tf.concat_5 (TFOpLambda)    (None, None, None, 768)      0         ['tf.repeat_1[0][0]',         \n",
      "                                                                     'model[0][1]']               \n",
      "                                                                                                  \n",
      " pa_fpn_p4p5_pre_conv (Conv  (None, None, None, 256)      196608    ['tf.concat_5[0][0]']         \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " pa_fpn_p4p5_pre_bn (BatchN  (None, None, None, 256)      1024      ['pa_fpn_p4p5_pre_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " pa_fpn_p4p5_pre (Activatio  (None, None, None, 256)      0         ['pa_fpn_p4p5_pre_bn[0][0]']  \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " tf.split_4 (TFOpLambda)     [(None, None, None, 128),    0         ['pa_fpn_p4p5_pre[0][0]']     \n",
      "                              (None, None, None, 128)]                                            \n",
      "                                                                                                  \n",
      " pa_fpn_p4p5_pre_0_1_pad (Z  (None, None, None, 128)      0         ['tf.split_4[0][1]']          \n",
      " eroPadding2D)                                                                                    \n",
      "                                                                                                  \n",
      " pa_fpn_p4p5_pre_0_1_conv (  (None, None, None, 128)      147456    ['pa_fpn_p4p5_pre_0_1_pad[0][0\n",
      " Conv2D)                                                            ]']                           \n",
      "                                                                                                  \n",
      " pa_fpn_p4p5_pre_0_1_bn (Ba  (None, None, None, 128)      512       ['pa_fpn_p4p5_pre_0_1_conv[0][\n",
      " tchNormalization)                                                  0]']                          \n",
      "                                                                                                  \n",
      " pa_fpn_p4p5_pre_0_1 (Activ  (None, None, None, 128)      0         ['pa_fpn_p4p5_pre_0_1_bn[0][0]\n",
      " ation)                                                             ']                            \n",
      "                                                                                                  \n",
      " pa_fpn_p4p5_pre_0_2_pad (Z  (None, None, None, 128)      0         ['pa_fpn_p4p5_pre_0_1[0][0]'] \n",
      " eroPadding2D)                                                                                    \n",
      "                                                                                                  \n",
      " pa_fpn_p4p5_pre_0_2_conv (  (None, None, None, 128)      147456    ['pa_fpn_p4p5_pre_0_2_pad[0][0\n",
      " Conv2D)                                                            ]']                           \n",
      "                                                                                                  \n",
      " pa_fpn_p4p5_pre_0_2_bn (Ba  (None, None, None, 128)      512       ['pa_fpn_p4p5_pre_0_2_conv[0][\n",
      " tchNormalization)                                                  0]']                          \n",
      "                                                                                                  \n",
      " pa_fpn_p4p5_pre_0_2 (Activ  (None, None, None, 128)      0         ['pa_fpn_p4p5_pre_0_2_bn[0][0]\n",
      " ation)                                                             ']                            \n",
      "                                                                                                  \n",
      " tf.concat_6 (TFOpLambda)    (None, None, None, 384)      0         ['tf.split_4[0][0]',          \n",
      "                                                                     'tf.split_4[0][1]',          \n",
      "                                                                     'pa_fpn_p4p5_pre_0_2[0][0]'] \n",
      "                                                                                                  \n",
      " pa_fpn_p4p5_output_conv (C  (None, None, None, 256)      98304     ['tf.concat_6[0][0]']         \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " pa_fpn_p4p5_output_bn (Bat  (None, None, None, 256)      1024      ['pa_fpn_p4p5_output_conv[0][0\n",
      " chNormalization)                                                   ]']                           \n",
      "                                                                                                  \n",
      " pa_fpn_p4p5_output (Activa  (None, None, None, 256)      0         ['pa_fpn_p4p5_output_bn[0][0]'\n",
      " tion)                                                              ]                             \n",
      "                                                                                                  \n",
      " tf.repeat_2 (TFOpLambda)    (None, None, None, 256)      0         ['pa_fpn_p4p5_output[0][0]']  \n",
      "                                                                                                  \n",
      " tf.repeat_3 (TFOpLambda)    (None, None, None, 256)      0         ['tf.repeat_2[0][0]']         \n",
      "                                                                                                  \n",
      " tf.concat_7 (TFOpLambda)    (None, None, None, 384)      0         ['tf.repeat_3[0][0]',         \n",
      "                                                                     'model[0][0]']               \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_pre_conv (Co  (None, None, None, 128)      49152     ['tf.concat_7[0][0]']         \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_pre_bn (Batc  (None, None, None, 128)      512       ['pa_fpn_p3p4p5_pre_conv[0][0]\n",
      " hNormalization)                                                    ']                            \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_pre (Activat  (None, None, None, 128)      0         ['pa_fpn_p3p4p5_pre_bn[0][0]']\n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " tf.split_5 (TFOpLambda)     [(None, None, None, 64),     0         ['pa_fpn_p3p4p5_pre[0][0]']   \n",
      "                              (None, None, None, 64)]                                             \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_pre_0_1_pad   (None, None, None, 64)       0         ['tf.split_5[0][1]']          \n",
      " (ZeroPadding2D)                                                                                  \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_pre_0_1_conv  (None, None, None, 64)       36864     ['pa_fpn_p3p4p5_pre_0_1_pad[0]\n",
      "  (Conv2D)                                                          [0]']                         \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_pre_0_1_bn (  (None, None, None, 64)       256       ['pa_fpn_p3p4p5_pre_0_1_conv[0\n",
      " BatchNormalization)                                                ][0]']                        \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_pre_0_1 (Act  (None, None, None, 64)       0         ['pa_fpn_p3p4p5_pre_0_1_bn[0][\n",
      " ivation)                                                           0]']                          \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_pre_0_2_pad   (None, None, None, 64)       0         ['pa_fpn_p3p4p5_pre_0_1[0][0]'\n",
      " (ZeroPadding2D)                                                    ]                             \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_pre_0_2_conv  (None, None, None, 64)       36864     ['pa_fpn_p3p4p5_pre_0_2_pad[0]\n",
      "  (Conv2D)                                                          [0]']                         \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_pre_0_2_bn (  (None, None, None, 64)       256       ['pa_fpn_p3p4p5_pre_0_2_conv[0\n",
      " BatchNormalization)                                                ][0]']                        \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_pre_0_2 (Act  (None, None, None, 64)       0         ['pa_fpn_p3p4p5_pre_0_2_bn[0][\n",
      " ivation)                                                           0]']                          \n",
      "                                                                                                  \n",
      " tf.concat_8 (TFOpLambda)    (None, None, None, 192)      0         ['tf.split_5[0][0]',          \n",
      "                                                                     'tf.split_5[0][1]',          \n",
      "                                                                     'pa_fpn_p3p4p5_pre_0_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_output_conv   (None, None, None, 128)      24576     ['tf.concat_8[0][0]']         \n",
      " (Conv2D)                                                                                         \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_output_bn (B  (None, None, None, 128)      512       ['pa_fpn_p3p4p5_output_conv[0]\n",
      " atchNormalization)                                                 [0]']                         \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_output (Acti  (None, None, None, 128)      0         ['pa_fpn_p3p4p5_output_bn[0][0\n",
      " vation)                                                            ]']                           \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample1_  (None, None, None, 128)      0         ['pa_fpn_p3p4p5_output[0][0]']\n",
      " pad (ZeroPadding2D)                                                                              \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample1_  (None, None, None, 128)      147456    ['pa_fpn_p3p4p5_downsample1_pa\n",
      " conv (Conv2D)                                                      d[0][0]']                     \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample1_  (None, None, None, 128)      512       ['pa_fpn_p3p4p5_downsample1_co\n",
      " bn (BatchNormalization)                                            nv[0][0]']                    \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample1   (None, None, None, 128)      0         ['pa_fpn_p3p4p5_downsample1_bn\n",
      " (Activation)                                                       [0][0]']                      \n",
      "                                                                                                  \n",
      " tf.concat_9 (TFOpLambda)    (None, None, None, 384)      0         ['pa_fpn_p3p4p5_downsample1[0]\n",
      "                                                                    [0]',                         \n",
      "                                                                     'pa_fpn_p4p5_output[0][0]']  \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample1_  (None, None, None, 256)      98304     ['tf.concat_9[0][0]']         \n",
      " block_pre_conv (Conv2D)                                                                          \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample1_  (None, None, None, 256)      1024      ['pa_fpn_p3p4p5_downsample1_bl\n",
      " block_pre_bn (BatchNormali                                         ock_pre_conv[0][0]']          \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample1_  (None, None, None, 256)      0         ['pa_fpn_p3p4p5_downsample1_bl\n",
      " block_pre (Activation)                                             ock_pre_bn[0][0]']            \n",
      "                                                                                                  \n",
      " tf.split_6 (TFOpLambda)     [(None, None, None, 128),    0         ['pa_fpn_p3p4p5_downsample1_bl\n",
      "                              (None, None, None, 128)]              ock_pre[0][0]']               \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample1_  (None, None, None, 128)      0         ['tf.split_6[0][1]']          \n",
      " block_pre_0_1_pad (ZeroPad                                                                       \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample1_  (None, None, None, 128)      147456    ['pa_fpn_p3p4p5_downsample1_bl\n",
      " block_pre_0_1_conv (Conv2D                                         ock_pre_0_1_pad[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample1_  (None, None, None, 128)      512       ['pa_fpn_p3p4p5_downsample1_bl\n",
      " block_pre_0_1_bn (BatchNor                                         ock_pre_0_1_conv[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample1_  (None, None, None, 128)      0         ['pa_fpn_p3p4p5_downsample1_bl\n",
      " block_pre_0_1 (Activation)                                         ock_pre_0_1_bn[0][0]']        \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample1_  (None, None, None, 128)      0         ['pa_fpn_p3p4p5_downsample1_bl\n",
      " block_pre_0_2_pad (ZeroPad                                         ock_pre_0_1[0][0]']           \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample1_  (None, None, None, 128)      147456    ['pa_fpn_p3p4p5_downsample1_bl\n",
      " block_pre_0_2_conv (Conv2D                                         ock_pre_0_2_pad[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample1_  (None, None, None, 128)      512       ['pa_fpn_p3p4p5_downsample1_bl\n",
      " block_pre_0_2_bn (BatchNor                                         ock_pre_0_2_conv[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample1_  (None, None, None, 128)      0         ['pa_fpn_p3p4p5_downsample1_bl\n",
      " block_pre_0_2 (Activation)                                         ock_pre_0_2_bn[0][0]']        \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample1_  (None, None, None, 128)      0         ['pa_fpn_p3p4p5_downsample1_bl\n",
      " block_pre_1_1_pad (ZeroPad                                         ock_pre_0_2[0][0]']           \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample1_  (None, None, None, 128)      147456    ['pa_fpn_p3p4p5_downsample1_bl\n",
      " block_pre_1_1_conv (Conv2D                                         ock_pre_1_1_pad[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample1_  (None, None, None, 128)      512       ['pa_fpn_p3p4p5_downsample1_bl\n",
      " block_pre_1_1_bn (BatchNor                                         ock_pre_1_1_conv[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample1_  (None, None, None, 128)      0         ['pa_fpn_p3p4p5_downsample1_bl\n",
      " block_pre_1_1 (Activation)                                         ock_pre_1_1_bn[0][0]']        \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample1_  (None, None, None, 128)      0         ['pa_fpn_p3p4p5_downsample1_bl\n",
      " block_pre_1_2_pad (ZeroPad                                         ock_pre_1_1[0][0]']           \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample1_  (None, None, None, 128)      147456    ['pa_fpn_p3p4p5_downsample1_bl\n",
      " block_pre_1_2_conv (Conv2D                                         ock_pre_1_2_pad[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample1_  (None, None, None, 128)      512       ['pa_fpn_p3p4p5_downsample1_bl\n",
      " block_pre_1_2_bn (BatchNor                                         ock_pre_1_2_conv[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample1_  (None, None, None, 128)      0         ['pa_fpn_p3p4p5_downsample1_bl\n",
      " block_pre_1_2 (Activation)                                         ock_pre_1_2_bn[0][0]']        \n",
      "                                                                                                  \n",
      " tf.concat_10 (TFOpLambda)   (None, None, None, 512)      0         ['tf.split_6[0][0]',          \n",
      "                                                                     'tf.split_6[0][1]',          \n",
      "                                                                     'pa_fpn_p3p4p5_downsample1_bl\n",
      "                                                                    ock_pre_0_2[0][0]',           \n",
      "                                                                     'pa_fpn_p3p4p5_downsample1_bl\n",
      "                                                                    ock_pre_1_2[0][0]']           \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample1_  (None, None, None, 256)      131072    ['tf.concat_10[0][0]']        \n",
      " block_output_conv (Conv2D)                                                                       \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample1_  (None, None, None, 256)      1024      ['pa_fpn_p3p4p5_downsample1_bl\n",
      " block_output_bn (BatchNorm                                         ock_output_conv[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample1_  (None, None, None, 256)      0         ['pa_fpn_p3p4p5_downsample1_bl\n",
      " block_output (Activation)                                          ock_output_bn[0][0]']         \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample2_  (None, None, None, 256)      0         ['pa_fpn_p3p4p5_downsample1_bl\n",
      " pad (ZeroPadding2D)                                                ock_output[0][0]']            \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample2_  (None, None, None, 256)      589824    ['pa_fpn_p3p4p5_downsample2_pa\n",
      " conv (Conv2D)                                                      d[0][0]']                     \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample2_  (None, None, None, 256)      1024      ['pa_fpn_p3p4p5_downsample2_co\n",
      " bn (BatchNormalization)                                            nv[0][0]']                    \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample2   (None, None, None, 256)      0         ['pa_fpn_p3p4p5_downsample2_bn\n",
      " (Activation)                                                       [0][0]']                      \n",
      "                                                                                                  \n",
      " tf.concat_11 (TFOpLambda)   (None, None, None, 768)      0         ['pa_fpn_p3p4p5_downsample2[0]\n",
      "                                                                    [0]',                         \n",
      "                                                                     'model[0][2]']               \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample2_  (None, None, None, 512)      393216    ['tf.concat_11[0][0]']        \n",
      " block_pre_conv (Conv2D)                                                                          \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample2_  (None, None, None, 512)      2048      ['pa_fpn_p3p4p5_downsample2_bl\n",
      " block_pre_bn (BatchNormali                                         ock_pre_conv[0][0]']          \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample2_  (None, None, None, 512)      0         ['pa_fpn_p3p4p5_downsample2_bl\n",
      " block_pre (Activation)                                             ock_pre_bn[0][0]']            \n",
      "                                                                                                  \n",
      " tf.split_7 (TFOpLambda)     [(None, None, None, 256),    0         ['pa_fpn_p3p4p5_downsample2_bl\n",
      "                              (None, None, None, 256)]              ock_pre[0][0]']               \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample2_  (None, None, None, 256)      0         ['tf.split_7[0][1]']          \n",
      " block_pre_0_1_pad (ZeroPad                                                                       \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample2_  (None, None, None, 256)      589824    ['pa_fpn_p3p4p5_downsample2_bl\n",
      " block_pre_0_1_conv (Conv2D                                         ock_pre_0_1_pad[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample2_  (None, None, None, 256)      1024      ['pa_fpn_p3p4p5_downsample2_bl\n",
      " block_pre_0_1_bn (BatchNor                                         ock_pre_0_1_conv[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample2_  (None, None, None, 256)      0         ['pa_fpn_p3p4p5_downsample2_bl\n",
      " block_pre_0_1 (Activation)                                         ock_pre_0_1_bn[0][0]']        \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample2_  (None, None, None, 256)      0         ['pa_fpn_p3p4p5_downsample2_bl\n",
      " block_pre_0_2_pad (ZeroPad                                         ock_pre_0_1[0][0]']           \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample2_  (None, None, None, 256)      589824    ['pa_fpn_p3p4p5_downsample2_bl\n",
      " block_pre_0_2_conv (Conv2D                                         ock_pre_0_2_pad[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample2_  (None, None, None, 256)      1024      ['pa_fpn_p3p4p5_downsample2_bl\n",
      " block_pre_0_2_bn (BatchNor                                         ock_pre_0_2_conv[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample2_  (None, None, None, 256)      0         ['pa_fpn_p3p4p5_downsample2_bl\n",
      " block_pre_0_2 (Activation)                                         ock_pre_0_2_bn[0][0]']        \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample2_  (None, None, None, 256)      0         ['pa_fpn_p3p4p5_downsample2_bl\n",
      " block_pre_1_1_pad (ZeroPad                                         ock_pre_0_2[0][0]']           \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample2_  (None, None, None, 256)      589824    ['pa_fpn_p3p4p5_downsample2_bl\n",
      " block_pre_1_1_conv (Conv2D                                         ock_pre_1_1_pad[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample2_  (None, None, None, 256)      1024      ['pa_fpn_p3p4p5_downsample2_bl\n",
      " block_pre_1_1_bn (BatchNor                                         ock_pre_1_1_conv[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample2_  (None, None, None, 256)      0         ['pa_fpn_p3p4p5_downsample2_bl\n",
      " block_pre_1_1 (Activation)                                         ock_pre_1_1_bn[0][0]']        \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample2_  (None, None, None, 256)      0         ['pa_fpn_p3p4p5_downsample2_bl\n",
      " block_pre_1_2_pad (ZeroPad                                         ock_pre_1_1[0][0]']           \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample2_  (None, None, None, 256)      589824    ['pa_fpn_p3p4p5_downsample2_bl\n",
      " block_pre_1_2_conv (Conv2D                                         ock_pre_1_2_pad[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample2_  (None, None, None, 256)      1024      ['pa_fpn_p3p4p5_downsample2_bl\n",
      " block_pre_1_2_bn (BatchNor                                         ock_pre_1_2_conv[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample2_  (None, None, None, 256)      0         ['pa_fpn_p3p4p5_downsample2_bl\n",
      " block_pre_1_2 (Activation)                                         ock_pre_1_2_bn[0][0]']        \n",
      "                                                                                                  \n",
      " tf.concat_12 (TFOpLambda)   (None, None, None, 1024)     0         ['tf.split_7[0][0]',          \n",
      "                                                                     'tf.split_7[0][1]',          \n",
      "                                                                     'pa_fpn_p3p4p5_downsample2_bl\n",
      "                                                                    ock_pre_0_2[0][0]',           \n",
      "                                                                     'pa_fpn_p3p4p5_downsample2_bl\n",
      "                                                                    ock_pre_1_2[0][0]']           \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample2_  (None, None, None, 512)      524288    ['tf.concat_12[0][0]']        \n",
      " block_output_conv (Conv2D)                                                                       \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample2_  (None, None, None, 512)      2048      ['pa_fpn_p3p4p5_downsample2_bl\n",
      " block_output_bn (BatchNorm                                         ock_output_conv[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample2_  (None, None, None, 512)      0         ['pa_fpn_p3p4p5_downsample2_bl\n",
      " block_output (Activation)                                          ock_output_bn[0][0]']         \n",
      "                                                                                                  \n",
      " yolo_v8_head_1_class_1_pad  (None, None, None, 128)      0         ['pa_fpn_p3p4p5_output[0][0]']\n",
      "  (ZeroPadding2D)                                                                                 \n",
      "                                                                                                  \n",
      " yolo_v8_head_2_class_1_pad  (None, None, None, 256)      0         ['pa_fpn_p3p4p5_downsample1_bl\n",
      "  (ZeroPadding2D)                                                   ock_output[0][0]']            \n",
      "                                                                                                  \n",
      " yolo_v8_head_3_class_1_pad  (None, None, None, 512)      0         ['pa_fpn_p3p4p5_downsample2_bl\n",
      "  (ZeroPadding2D)                                                   ock_output[0][0]']            \n",
      "                                                                                                  \n",
      " yolo_v8_head_1_box_1_pad (  (None, None, None, 128)      0         ['pa_fpn_p3p4p5_output[0][0]']\n",
      " ZeroPadding2D)                                                                                   \n",
      "                                                                                                  \n",
      " yolo_v8_head_1_class_1_con  (None, None, None, 128)      147456    ['yolo_v8_head_1_class_1_pad[0\n",
      " v (Conv2D)                                                         ][0]']                        \n",
      "                                                                                                  \n",
      " yolo_v8_head_2_box_1_pad (  (None, None, None, 256)      0         ['pa_fpn_p3p4p5_downsample1_bl\n",
      " ZeroPadding2D)                                                     ock_output[0][0]']            \n",
      "                                                                                                  \n",
      " yolo_v8_head_2_class_1_con  (None, None, None, 128)      294912    ['yolo_v8_head_2_class_1_pad[0\n",
      " v (Conv2D)                                                         ][0]']                        \n",
      "                                                                                                  \n",
      " yolo_v8_head_3_box_1_pad (  (None, None, None, 512)      0         ['pa_fpn_p3p4p5_downsample2_bl\n",
      " ZeroPadding2D)                                                     ock_output[0][0]']            \n",
      "                                                                                                  \n",
      " yolo_v8_head_3_class_1_con  (None, None, None, 128)      589824    ['yolo_v8_head_3_class_1_pad[0\n",
      " v (Conv2D)                                                         ][0]']                        \n",
      "                                                                                                  \n",
      " yolo_v8_head_1_box_1_conv   (None, None, None, 64)       73728     ['yolo_v8_head_1_box_1_pad[0][\n",
      " (Conv2D)                                                           0]']                          \n",
      "                                                                                                  \n",
      " yolo_v8_head_1_class_1_bn   (None, None, None, 128)      512       ['yolo_v8_head_1_class_1_conv[\n",
      " (BatchNormalization)                                               0][0]']                       \n",
      "                                                                                                  \n",
      " yolo_v8_head_2_box_1_conv   (None, None, None, 64)       147456    ['yolo_v8_head_2_box_1_pad[0][\n",
      " (Conv2D)                                                           0]']                          \n",
      "                                                                                                  \n",
      " yolo_v8_head_2_class_1_bn   (None, None, None, 128)      512       ['yolo_v8_head_2_class_1_conv[\n",
      " (BatchNormalization)                                               0][0]']                       \n",
      "                                                                                                  \n",
      " yolo_v8_head_3_box_1_conv   (None, None, None, 64)       294912    ['yolo_v8_head_3_box_1_pad[0][\n",
      " (Conv2D)                                                           0]']                          \n",
      "                                                                                                  \n",
      " yolo_v8_head_3_class_1_bn   (None, None, None, 128)      512       ['yolo_v8_head_3_class_1_conv[\n",
      " (BatchNormalization)                                               0][0]']                       \n",
      "                                                                                                  \n",
      " yolo_v8_head_1_box_1_bn (B  (None, None, None, 64)       256       ['yolo_v8_head_1_box_1_conv[0]\n",
      " atchNormalization)                                                 [0]']                         \n",
      "                                                                                                  \n",
      " yolo_v8_head_1_class_1 (Ac  (None, None, None, 128)      0         ['yolo_v8_head_1_class_1_bn[0]\n",
      " tivation)                                                          [0]']                         \n",
      "                                                                                                  \n",
      " yolo_v8_head_2_box_1_bn (B  (None, None, None, 64)       256       ['yolo_v8_head_2_box_1_conv[0]\n",
      " atchNormalization)                                                 [0]']                         \n",
      "                                                                                                  \n",
      " yolo_v8_head_2_class_1 (Ac  (None, None, None, 128)      0         ['yolo_v8_head_2_class_1_bn[0]\n",
      " tivation)                                                          [0]']                         \n",
      "                                                                                                  \n",
      " yolo_v8_head_3_box_1_bn (B  (None, None, None, 64)       256       ['yolo_v8_head_3_box_1_conv[0]\n",
      " atchNormalization)                                                 [0]']                         \n",
      "                                                                                                  \n",
      " yolo_v8_head_3_class_1 (Ac  (None, None, None, 128)      0         ['yolo_v8_head_3_class_1_bn[0]\n",
      " tivation)                                                          [0]']                         \n",
      "                                                                                                  \n",
      " yolo_v8_head_1_box_1 (Acti  (None, None, None, 64)       0         ['yolo_v8_head_1_box_1_bn[0][0\n",
      " vation)                                                            ]']                           \n",
      "                                                                                                  \n",
      " yolo_v8_head_1_class_2_pad  (None, None, None, 128)      0         ['yolo_v8_head_1_class_1[0][0]\n",
      "  (ZeroPadding2D)                                                   ']                            \n",
      "                                                                                                  \n",
      " yolo_v8_head_2_box_1 (Acti  (None, None, None, 64)       0         ['yolo_v8_head_2_box_1_bn[0][0\n",
      " vation)                                                            ]']                           \n",
      "                                                                                                  \n",
      " yolo_v8_head_2_class_2_pad  (None, None, None, 128)      0         ['yolo_v8_head_2_class_1[0][0]\n",
      "  (ZeroPadding2D)                                                   ']                            \n",
      "                                                                                                  \n",
      " yolo_v8_head_3_box_1 (Acti  (None, None, None, 64)       0         ['yolo_v8_head_3_box_1_bn[0][0\n",
      " vation)                                                            ]']                           \n",
      "                                                                                                  \n",
      " yolo_v8_head_3_class_2_pad  (None, None, None, 128)      0         ['yolo_v8_head_3_class_1[0][0]\n",
      "  (ZeroPadding2D)                                                   ']                            \n",
      "                                                                                                  \n",
      " yolo_v8_head_1_box_2_pad (  (None, None, None, 64)       0         ['yolo_v8_head_1_box_1[0][0]']\n",
      " ZeroPadding2D)                                                                                   \n",
      "                                                                                                  \n",
      " yolo_v8_head_1_class_2_con  (None, None, None, 128)      147456    ['yolo_v8_head_1_class_2_pad[0\n",
      " v (Conv2D)                                                         ][0]']                        \n",
      "                                                                                                  \n",
      " yolo_v8_head_2_box_2_pad (  (None, None, None, 64)       0         ['yolo_v8_head_2_box_1[0][0]']\n",
      " ZeroPadding2D)                                                                                   \n",
      "                                                                                                  \n",
      " yolo_v8_head_2_class_2_con  (None, None, None, 128)      147456    ['yolo_v8_head_2_class_2_pad[0\n",
      " v (Conv2D)                                                         ][0]']                        \n",
      "                                                                                                  \n",
      " yolo_v8_head_3_box_2_pad (  (None, None, None, 64)       0         ['yolo_v8_head_3_box_1[0][0]']\n",
      " ZeroPadding2D)                                                                                   \n",
      "                                                                                                  \n",
      " yolo_v8_head_3_class_2_con  (None, None, None, 128)      147456    ['yolo_v8_head_3_class_2_pad[0\n",
      " v (Conv2D)                                                         ][0]']                        \n",
      "                                                                                                  \n",
      " yolo_v8_head_1_box_2_conv   (None, None, None, 64)       36864     ['yolo_v8_head_1_box_2_pad[0][\n",
      " (Conv2D)                                                           0]']                          \n",
      "                                                                                                  \n",
      " yolo_v8_head_1_class_2_bn   (None, None, None, 128)      512       ['yolo_v8_head_1_class_2_conv[\n",
      " (BatchNormalization)                                               0][0]']                       \n",
      "                                                                                                  \n",
      " yolo_v8_head_2_box_2_conv   (None, None, None, 64)       36864     ['yolo_v8_head_2_box_2_pad[0][\n",
      " (Conv2D)                                                           0]']                          \n",
      "                                                                                                  \n",
      " yolo_v8_head_2_class_2_bn   (None, None, None, 128)      512       ['yolo_v8_head_2_class_2_conv[\n",
      " (BatchNormalization)                                               0][0]']                       \n",
      "                                                                                                  \n",
      " yolo_v8_head_3_box_2_conv   (None, None, None, 64)       36864     ['yolo_v8_head_3_box_2_pad[0][\n",
      " (Conv2D)                                                           0]']                          \n",
      "                                                                                                  \n",
      " yolo_v8_head_3_class_2_bn   (None, None, None, 128)      512       ['yolo_v8_head_3_class_2_conv[\n",
      " (BatchNormalization)                                               0][0]']                       \n",
      "                                                                                                  \n",
      " yolo_v8_head_1_box_2_bn (B  (None, None, None, 64)       256       ['yolo_v8_head_1_box_2_conv[0]\n",
      " atchNormalization)                                                 [0]']                         \n",
      "                                                                                                  \n",
      " yolo_v8_head_1_class_2 (Ac  (None, None, None, 128)      0         ['yolo_v8_head_1_class_2_bn[0]\n",
      " tivation)                                                          [0]']                         \n",
      "                                                                                                  \n",
      " yolo_v8_head_2_box_2_bn (B  (None, None, None, 64)       256       ['yolo_v8_head_2_box_2_conv[0]\n",
      " atchNormalization)                                                 [0]']                         \n",
      "                                                                                                  \n",
      " yolo_v8_head_2_class_2 (Ac  (None, None, None, 128)      0         ['yolo_v8_head_2_class_2_bn[0]\n",
      " tivation)                                                          [0]']                         \n",
      "                                                                                                  \n",
      " yolo_v8_head_3_box_2_bn (B  (None, None, None, 64)       256       ['yolo_v8_head_3_box_2_conv[0]\n",
      " atchNormalization)                                                 [0]']                         \n",
      "                                                                                                  \n",
      " yolo_v8_head_3_class_2 (Ac  (None, None, None, 128)      0         ['yolo_v8_head_3_class_2_bn[0]\n",
      " tivation)                                                          [0]']                         \n",
      "                                                                                                  \n",
      " yolo_v8_head_1_box_2 (Acti  (None, None, None, 64)       0         ['yolo_v8_head_1_box_2_bn[0][0\n",
      " vation)                                                            ]']                           \n",
      "                                                                                                  \n",
      " yolo_v8_head_1_class_3_con  (None, None, None, 2)        258       ['yolo_v8_head_1_class_2[0][0]\n",
      " v (Conv2D)                                                         ']                            \n",
      "                                                                                                  \n",
      " yolo_v8_head_2_box_2 (Acti  (None, None, None, 64)       0         ['yolo_v8_head_2_box_2_bn[0][0\n",
      " vation)                                                            ]']                           \n",
      "                                                                                                  \n",
      " yolo_v8_head_2_class_3_con  (None, None, None, 2)        258       ['yolo_v8_head_2_class_2[0][0]\n",
      " v (Conv2D)                                                         ']                            \n",
      "                                                                                                  \n",
      " yolo_v8_head_3_box_2 (Acti  (None, None, None, 64)       0         ['yolo_v8_head_3_box_2_bn[0][0\n",
      " vation)                                                            ]']                           \n",
      "                                                                                                  \n",
      " yolo_v8_head_3_class_3_con  (None, None, None, 2)        258       ['yolo_v8_head_3_class_2[0][0]\n",
      " v (Conv2D)                                                         ']                            \n",
      "                                                                                                  \n",
      " yolo_v8_head_1_box_3_conv   (None, None, None, 64)       4160      ['yolo_v8_head_1_box_2[0][0]']\n",
      " (Conv2D)                                                                                         \n",
      "                                                                                                  \n",
      " yolo_v8_head_1_classifier   (None, None, None, 2)        0         ['yolo_v8_head_1_class_3_conv[\n",
      " (Activation)                                                       0][0]']                       \n",
      "                                                                                                  \n",
      " yolo_v8_head_2_box_3_conv   (None, None, None, 64)       4160      ['yolo_v8_head_2_box_2[0][0]']\n",
      " (Conv2D)                                                                                         \n",
      "                                                                                                  \n",
      " yolo_v8_head_2_classifier   (None, None, None, 2)        0         ['yolo_v8_head_2_class_3_conv[\n",
      " (Activation)                                                       0][0]']                       \n",
      "                                                                                                  \n",
      " yolo_v8_head_3_box_3_conv   (None, None, None, 64)       4160      ['yolo_v8_head_3_box_2[0][0]']\n",
      " (Conv2D)                                                                                         \n",
      "                                                                                                  \n",
      " yolo_v8_head_3_classifier   (None, None, None, 2)        0         ['yolo_v8_head_3_class_3_conv[\n",
      " (Activation)                                                       0][0]']                       \n",
      "                                                                                                  \n",
      " tf.concat_13 (TFOpLambda)   (None, None, None, 66)       0         ['yolo_v8_head_1_box_3_conv[0]\n",
      "                                                                    [0]',                         \n",
      "                                                                     'yolo_v8_head_1_classifier[0]\n",
      "                                                                    [0]']                         \n",
      "                                                                                                  \n",
      " tf.concat_14 (TFOpLambda)   (None, None, None, 66)       0         ['yolo_v8_head_2_box_3_conv[0]\n",
      "                                                                    [0]',                         \n",
      "                                                                     'yolo_v8_head_2_classifier[0]\n",
      "                                                                    [0]']                         \n",
      "                                                                                                  \n",
      " tf.concat_15 (TFOpLambda)   (None, None, None, 66)       0         ['yolo_v8_head_3_box_3_conv[0]\n",
      "                                                                    [0]',                         \n",
      "                                                                     'yolo_v8_head_3_classifier[0]\n",
      "                                                                    [0]']                         \n",
      "                                                                                                  \n",
      " yolo_v8_head_1_output_resh  (None, None, 66)             0         ['tf.concat_13[0][0]']        \n",
      " ape (Reshape)                                                                                    \n",
      "                                                                                                  \n",
      " yolo_v8_head_2_output_resh  (None, None, 66)             0         ['tf.concat_14[0][0]']        \n",
      " ape (Reshape)                                                                                    \n",
      "                                                                                                  \n",
      " yolo_v8_head_3_output_resh  (None, None, 66)             0         ['tf.concat_15[0][0]']        \n",
      " ape (Reshape)                                                                                    \n",
      "                                                                                                  \n",
      " tf.concat_16 (TFOpLambda)   (None, None, 66)             0         ['yolo_v8_head_1_output_reshap\n",
      "                                                                    e[0][0]',                     \n",
      "                                                                     'yolo_v8_head_2_output_reshap\n",
      "                                                                    e[0][0]',                     \n",
      "                                                                     'yolo_v8_head_3_output_reshap\n",
      "                                                                    e[0][0]']                     \n",
      "                                                                                                  \n",
      " box_outputs (Activation)    (None, None, 66)             0         ['tf.concat_16[0][0]']        \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (  (None, None, 64)             0         ['box_outputs[0][0]']         \n",
      " SlicingOpLambda)                                                                                 \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1  (None, None, 2)              0         ['box_outputs[0][0]']         \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " box (Concatenate)           (None, None, 64)             0         ['tf.__operators__.getitem[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " class (Concatenate)         (None, None, 2)              0         ['tf.__operators__.getitem_1[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " non_max_suppression (NonMa  multiple                     0         []                            \n",
      " xSuppression)                                                                                    \n",
      "                                                                                                  \n",
      " yolov8_label_encoder (YOLO  multiple                     0         []                            \n",
      " V8LabelEncoder)                                                                                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 17877574 (68.20 MB)\n",
      "Trainable params: 12776294 (48.74 MB)\n",
      "Non-trainable params: 5101280 (19.46 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "yolo = keras_cv.models.YOLOV8Detector(\n",
    "    num_classes=len(class_mapping),\n",
    "    bounding_box_format=\"xyxy\",\n",
    "    backbone=backbone,\n",
    "    fpn_depth=1\n",
    ")\n",
    "yolo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for layer in yolo.layers:\n",
    "#    if \"yolo_v8_head\" in layer.name:\n",
    "#        #print(layer.name + \" - \" + str(layer.trainable))\n",
    "#        layer.trainable = True\n",
    "#    else:\n",
    "#        layer.trainable = False\n",
    "#        \n",
    "#yolo.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AdGB9Hnc9vgu"
   },
   "source": [
    "## Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "sY6tk0O9MiAc"
   },
   "outputs": [],
   "source": [
    "#yolo.load_weights(\"model-s-onlyhead-test2.h5\")\n",
    "#yolo = keras_cv.models.load(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "srCan0bg9vgu"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.AdamW(\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    global_clipnorm=GLOBAL_CLIPNORM,\n",
    ")\n",
    "\n",
    "yolo.compile(\n",
    "    optimizer=optimizer, classification_loss=\"binary_crossentropy\", box_loss=\"ciou\"\n",
    ")\n",
    "#yolo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "C48F0vhG9vgu"
   },
   "outputs": [],
   "source": [
    "class EvaluateCOCOMetricsCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, data, save_path):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        self.metrics = keras_cv.metrics.BoxCOCOMetrics(\n",
    "            bounding_box_format=\"xyxy\",\n",
    "            evaluate_freq=1e9,\n",
    "        )\n",
    "\n",
    "        self.save_path = save_path\n",
    "        #self.best_map = -1.0\n",
    "        self.best_map = 999\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        self.metrics.reset_state()\n",
    "        #for batch in self.data:\n",
    "        #    images, y_true = batch[0], batch[1]\n",
    "        #    y_pred = self.model.predict(images, verbose=0)\n",
    "        #    self.metrics.update_state(y_true, y_pred)\n",
    "\n",
    "        #metrics = self.metrics.result(force=False)\n",
    "        #logs.update(metrics)\n",
    "\n",
    "        #print(metrics)\n",
    "        #current_map = metrics[\"MaP\"]\n",
    "        current_map = logs[\"val_loss\"]\n",
    "        if current_map < self.best_map:\n",
    "            self.best_map = current_map\n",
    "            now = datetime.now()\n",
    "            #self.model.save(self.save_path + \"-test2\"+ now.strftime(\"-%m%d%Y-%H%M%S\") + \".h5\")\n",
    "            self.model.save(self.save_path + \"-test2.h5\")\n",
    "\n",
    "        return logs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#yolo.save(\"model_3ep.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JlPTTQHy9vgu"
   },
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A7fqFHdG9vgu",
    "outputId": "13dd31b3-eb16-4cbd-8472-6a84a9a9d7bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 17:59:26.525972: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "2024-02-06 17:59:27.194581: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-02-06 17:59:30.252137: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-02-06 17:59:45.205899: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.05GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-02-06 17:59:45.287117: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.05GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-02-06 17:59:46.625765: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.16GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-02-06 17:59:46.718197: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.16GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-02-06 17:59:47.619693: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.10GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-02-06 17:59:47.699716: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.10GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-02-06 17:59:50.109137: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.17GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-02-06 17:59:50.219378: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.17GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-02-06 17:59:51.230892: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.13GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-02-06 17:59:51.344497: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.13GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-02-06 17:59:53.621223: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f96850c19b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-02-06 17:59:53.621303: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 Laptop GPU, Compute Capability 8.6\n",
      "2024-02-06 17:59:53.694385: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1707238793.851253   18383 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1912/1912 [==============================] - ETA: 0s - loss: 10.7402 - box_loss: 1.9373 - class_loss: 8.8029"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 18:06:33.843070: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 9830528 bytes after encountering the first element of size 9830528 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Found duplicated `Variable`s in Model's `weights`. This is usually caused by `Variable`s being shared by Layers in the Model. These `Variable`s will be treated as separate `Variable`s when the Model is restored. To avoid this, please save with `save_format=\"tf\"`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrea/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1912/1912 [==============================] - 491s 221ms/step - loss: 10.7402 - box_loss: 1.9373 - class_loss: 8.8029 - val_loss: 4.8350 - val_box_loss: 2.7123 - val_class_loss: 2.1227 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1912/1912 [==============================] - ETA: 0s - loss: 2.8654 - box_loss: 1.8566 - class_loss: 1.0089"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 18:13:36.087132: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 9830528 bytes after encountering the first element of size 9830528 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Found duplicated `Variable`s in Model's `weights`. This is usually caused by `Variable`s being shared by Layers in the Model. These `Variable`s will be treated as separate `Variable`s when the Model is restored. To avoid this, please save with `save_format=\"tf\"`.\n",
      "1912/1912 [==============================] - 416s 217ms/step - loss: 2.8654 - box_loss: 1.8566 - class_loss: 1.0089 - val_loss: 4.1260 - val_box_loss: 2.3302 - val_class_loss: 1.7958 - lr: 0.0010\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 18:14:05.888502: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 9830528 bytes after encountering the first element of size 9830528 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1912/1912 [==============================] - ETA: 0s - loss: 2.8156 - box_loss: 1.8018 - class_loss: 1.0138"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 18:20:29.043668: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 9830528 bytes after encountering the first element of size 9830528 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1912/1912 [==============================] - 411s 215ms/step - loss: 2.8156 - box_loss: 1.8018 - class_loss: 1.0138 - val_loss: 4.1739 - val_box_loss: 2.1304 - val_class_loss: 2.0436 - lr: 0.0010\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 18:20:57.526960: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 9830528 bytes after encountering the first element of size 9830528 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1912/1912 [==============================] - ETA: 0s - loss: 2.7005 - box_loss: 1.7470 - class_loss: 0.9535"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 18:27:21.950288: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 9830528 bytes after encountering the first element of size 9830528 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1912/1912 [==============================] - 412s 215ms/step - loss: 2.7005 - box_loss: 1.7470 - class_loss: 0.9535 - val_loss: 4.2433 - val_box_loss: 2.0996 - val_class_loss: 2.1437 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1912/1912 [==============================] - 417s 218ms/step - loss: 2.6709 - box_loss: 1.7161 - class_loss: 0.9549 - val_loss: 4.2067 - val_box_loss: 2.0522 - val_class_loss: 2.1546 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1912/1912 [==============================] - ETA: 0s - loss: 2.6141 - box_loss: 1.6858 - class_loss: 0.9283"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 18:41:17.104480: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 9830528 bytes after encountering the first element of size 9830528 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Found duplicated `Variable`s in Model's `weights`. This is usually caused by `Variable`s being shared by Layers in the Model. These `Variable`s will be treated as separate `Variable`s when the Model is restored. To avoid this, please save with `save_format=\"tf\"`.\n",
      "1912/1912 [==============================] - 418s 219ms/step - loss: 2.6141 - box_loss: 1.6858 - class_loss: 0.9283 - val_loss: 3.7478 - val_box_loss: 1.8149 - val_class_loss: 1.9329 - lr: 0.0010\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 18:41:46.997316: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 9830528 bytes after encountering the first element of size 9830528 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1912/1912 [==============================] - 409s 214ms/step - loss: 2.5222 - box_loss: 1.6422 - class_loss: 0.8800 - val_loss: 4.0699 - val_box_loss: 1.9163 - val_class_loss: 2.1535 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1912/1912 [==============================] - 405s 212ms/step - loss: 2.4401 - box_loss: 1.5965 - class_loss: 0.8436 - val_loss: 3.7797 - val_box_loss: 1.8096 - val_class_loss: 1.9701 - lr: 0.0010\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 18:55:22.336539: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 9830528 bytes after encountering the first element of size 9830528 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1912/1912 [==============================] - 405s 211ms/step - loss: 2.3933 - box_loss: 1.5827 - class_loss: 0.8106 - val_loss: 3.8248 - val_box_loss: 1.8275 - val_class_loss: 1.9973 - lr: 0.0010\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 19:02:07.386297: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 9830528 bytes after encountering the first element of size 9830528 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1912/1912 [==============================] - ETA: 0s - loss: 2.3165 - box_loss: 1.5408 - class_loss: 0.7757"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 19:08:24.106779: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 9830528 bytes after encountering the first element of size 9830528 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Found duplicated `Variable`s in Model's `weights`. This is usually caused by `Variable`s being shared by Layers in the Model. These `Variable`s will be treated as separate `Variable`s when the Model is restored. To avoid this, please save with `save_format=\"tf\"`.\n",
      "1912/1912 [==============================] - 407s 212ms/step - loss: 2.3165 - box_loss: 1.5408 - class_loss: 0.7757 - val_loss: 3.6432 - val_box_loss: 1.8059 - val_class_loss: 1.8373 - lr: 0.0010\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 19:08:54.518749: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 9830528 bytes after encountering the first element of size 9830528 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1912/1912 [==============================] - 402s 210ms/step - loss: 2.2617 - box_loss: 1.5020 - class_loss: 0.7597 - val_loss: 3.7609 - val_box_loss: 1.9527 - val_class_loss: 1.8082 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1912/1912 [==============================] - 403s 211ms/step - loss: 2.2172 - box_loss: 1.4826 - class_loss: 0.7347 - val_loss: 3.7639 - val_box_loss: 1.8228 - val_class_loss: 1.9411 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1912/1912 [==============================] - ETA: 0s - loss: 2.1868 - box_loss: 1.4655 - class_loss: 0.7213WARNING:tensorflow:Found duplicated `Variable`s in Model's `weights`. This is usually caused by `Variable`s being shared by Layers in the Model. These `Variable`s will be treated as separate `Variable`s when the Model is restored. To avoid this, please save with `save_format=\"tf\"`.\n",
      "1912/1912 [==============================] - 405s 212ms/step - loss: 2.1868 - box_loss: 1.4655 - class_loss: 0.7213 - val_loss: 3.5349 - val_box_loss: 1.8453 - val_class_loss: 1.6895 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1912/1912 [==============================] - 403s 210ms/step - loss: 2.1448 - box_loss: 1.4395 - class_loss: 0.7053 - val_loss: 3.6205 - val_box_loss: 1.7703 - val_class_loss: 1.8502 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "   1/1912 [..............................] - ETA: 16:20 - loss: 2.5772 - box_loss: 0.2567 - class_loss: 2.3205"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 19:35:48.529425: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 9830528 bytes after encountering the first element of size 9830528 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1912/1912 [==============================] - ETA: 0s - loss: 2.1167 - box_loss: 1.4238 - class_loss: 0.6929WARNING:tensorflow:Found duplicated `Variable`s in Model's `weights`. This is usually caused by `Variable`s being shared by Layers in the Model. These `Variable`s will be treated as separate `Variable`s when the Model is restored. To avoid this, please save with `save_format=\"tf\"`.\n",
      "1912/1912 [==============================] - 402s 210ms/step - loss: 2.1167 - box_loss: 1.4238 - class_loss: 0.6929 - val_loss: 3.4377 - val_box_loss: 1.7342 - val_class_loss: 1.7035 - lr: 0.0010\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 19:42:31.016192: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 9830528 bytes after encountering the first element of size 9830528 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1912/1912 [==============================] - 400s 209ms/step - loss: 2.0708 - box_loss: 1.4073 - class_loss: 0.6635 - val_loss: 3.8385 - val_box_loss: 1.9101 - val_class_loss: 1.9284 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1912/1912 [==============================] - ETA: 0s - loss: 2.0394 - box_loss: 1.3948 - class_loss: 0.6445"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 19:56:03.787408: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 9830528 bytes after encountering the first element of size 9830528 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1912/1912 [==============================] - 397s 207ms/step - loss: 2.0394 - box_loss: 1.3948 - class_loss: 0.6445 - val_loss: 3.6379 - val_box_loss: 1.7949 - val_class_loss: 1.8429 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1912/1912 [==============================] - 400s 209ms/step - loss: 2.0177 - box_loss: 1.3878 - class_loss: 0.6299 - val_loss: 3.6278 - val_box_loss: 1.8568 - val_class_loss: 1.7710 - lr: 0.0010\n",
      "Epoch 19/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 20:03:11.388720: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 9830528 bytes after encountering the first element of size 9830528 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1912/1912 [==============================] - ETA: 0s - loss: 2.0128 - box_loss: 1.3896 - class_loss: 0.6232"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 20:09:23.982936: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 9830528 bytes after encountering the first element of size 9830528 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1912/1912 [==============================] - 400s 209ms/step - loss: 2.0128 - box_loss: 1.3896 - class_loss: 0.6232 - val_loss: 3.4924 - val_box_loss: 1.7070 - val_class_loss: 1.7854 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "   1/1912 [..............................] - ETA: 16:12 - loss: 1.9411 - box_loss: 0.3714 - class_loss: 1.5696"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 20:09:51.498960: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 9830528 bytes after encountering the first element of size 9830528 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1912/1912 [==============================] - 401s 210ms/step - loss: 1.9654 - box_loss: 1.3497 - class_loss: 0.6158 - val_loss: 3.4712 - val_box_loss: 1.7217 - val_class_loss: 1.7495 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1912/1912 [==============================] - ETA: 0s - loss: 2.2265 - box_loss: 1.3912 - class_loss: 0.8353WARNING:tensorflow:Found duplicated `Variable`s in Model's `weights`. This is usually caused by `Variable`s being shared by Layers in the Model. These `Variable`s will be treated as separate `Variable`s when the Model is restored. To avoid this, please save with `save_format=\"tf\"`.\n",
      "1912/1912 [==============================] - 402s 210ms/step - loss: 2.2265 - box_loss: 1.3912 - class_loss: 0.8353 - val_loss: 2.8350 - val_box_loss: 1.6797 - val_class_loss: 1.1554 - lr: 1.0000e-04\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 20:23:15.552635: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 9830528 bytes after encountering the first element of size 9830528 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1912/1912 [==============================] - ETA: 0s - loss: 2.0447 - box_loss: 1.3424 - class_loss: 0.7023WARNING:tensorflow:Found duplicated `Variable`s in Model's `weights`. This is usually caused by `Variable`s being shared by Layers in the Model. These `Variable`s will be treated as separate `Variable`s when the Model is restored. To avoid this, please save with `save_format=\"tf\"`.\n",
      "1912/1912 [==============================] - 404s 211ms/step - loss: 2.0447 - box_loss: 1.3424 - class_loss: 0.7023 - val_loss: 2.7974 - val_box_loss: 1.6070 - val_class_loss: 1.1904 - lr: 1.0000e-04\n",
      "Epoch 23/50\n",
      "1912/1912 [==============================] - 402s 210ms/step - loss: 2.0093 - box_loss: 1.3436 - class_loss: 0.6657 - val_loss: 2.8606 - val_box_loss: 1.6080 - val_class_loss: 1.2526 - lr: 1.0000e-04\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 20:36:41.988413: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 9830528 bytes after encountering the first element of size 9830528 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1912/1912 [==============================] - 401s 209ms/step - loss: 1.9592 - box_loss: 1.3210 - class_loss: 0.6382 - val_loss: 2.9024 - val_box_loss: 1.6174 - val_class_loss: 1.2850 - lr: 1.0000e-04\n",
      "Epoch 25/50\n",
      "1912/1912 [==============================] - 401s 210ms/step - loss: 1.9270 - box_loss: 1.3129 - class_loss: 0.6141 - val_loss: 2.9305 - val_box_loss: 1.6122 - val_class_loss: 1.3183 - lr: 1.0000e-04\n",
      "Epoch 26/50\n",
      "1912/1912 [==============================] - 400s 209ms/step - loss: 1.8966 - box_loss: 1.2974 - class_loss: 0.5992 - val_loss: 2.9218 - val_box_loss: 1.5942 - val_class_loss: 1.3276 - lr: 1.0000e-04\n",
      "Epoch 27/50\n",
      "1912/1912 [==============================] - 396s 207ms/step - loss: 1.8886 - box_loss: 1.2956 - class_loss: 0.5930 - val_loss: 2.9365 - val_box_loss: 1.5858 - val_class_loss: 1.3508 - lr: 1.0000e-04\n",
      "Epoch 28/50\n",
      "1912/1912 [==============================] - ETA: 0s - loss: 2.1106 - box_loss: 1.3211 - class_loss: 0.7895WARNING:tensorflow:Found duplicated `Variable`s in Model's `weights`. This is usually caused by `Variable`s being shared by Layers in the Model. These `Variable`s will be treated as separate `Variable`s when the Model is restored. To avoid this, please save with `save_format=\"tf\"`.\n",
      "1912/1912 [==============================] - 401s 210ms/step - loss: 2.1106 - box_loss: 1.3211 - class_loss: 0.7895 - val_loss: 2.4694 - val_box_loss: 1.5118 - val_class_loss: 0.9575 - lr: 1.0000e-05\n",
      "Epoch 29/50\n",
      "1912/1912 [==============================] - ETA: 0s - loss: 1.9774 - box_loss: 1.2914 - class_loss: 0.6860WARNING:tensorflow:Found duplicated `Variable`s in Model's `weights`. This is usually caused by `Variable`s being shared by Layers in the Model. These `Variable`s will be treated as separate `Variable`s when the Model is restored. To avoid this, please save with `save_format=\"tf\"`.\n",
      "1912/1912 [==============================] - 402s 210ms/step - loss: 1.9774 - box_loss: 1.2914 - class_loss: 0.6860 - val_loss: 2.4414 - val_box_loss: 1.4901 - val_class_loss: 0.9513 - lr: 1.0000e-05\n",
      "Epoch 30/50\n",
      "1912/1912 [==============================] - ETA: 0s - loss: 1.9581 - box_loss: 1.2891 - class_loss: 0.6691WARNING:tensorflow:Found duplicated `Variable`s in Model's `weights`. This is usually caused by `Variable`s being shared by Layers in the Model. These `Variable`s will be treated as separate `Variable`s when the Model is restored. To avoid this, please save with `save_format=\"tf\"`.\n",
      "1912/1912 [==============================] - 402s 210ms/step - loss: 1.9581 - box_loss: 1.2891 - class_loss: 0.6691 - val_loss: 2.4220 - val_box_loss: 1.4951 - val_class_loss: 0.9269 - lr: 1.0000e-05\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 21:24:09.394012: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 9830528 bytes after encountering the first element of size 9830528 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1912/1912 [==============================] - ETA: 0s - loss: 1.9553 - box_loss: 1.2889 - class_loss: 0.6665"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 21:30:22.854946: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 9830528 bytes after encountering the first element of size 9830528 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1912/1912 [==============================] - 401s 209ms/step - loss: 1.9553 - box_loss: 1.2889 - class_loss: 0.6665 - val_loss: 2.4426 - val_box_loss: 1.4998 - val_class_loss: 0.9428 - lr: 1.0000e-05\n",
      "Epoch 32/50\n",
      "1912/1912 [==============================] - 400s 209ms/step - loss: 1.9412 - box_loss: 1.2849 - class_loss: 0.6563 - val_loss: 2.4797 - val_box_loss: 1.5042 - val_class_loss: 0.9755 - lr: 1.0000e-05\n",
      "Epoch 33/50\n",
      "1912/1912 [==============================] - 400s 209ms/step - loss: 1.9496 - box_loss: 1.2985 - class_loss: 0.6511 - val_loss: 2.4605 - val_box_loss: 1.4918 - val_class_loss: 0.9687 - lr: 1.0000e-05\n",
      "Epoch 34/50\n",
      "1912/1912 [==============================] - 399s 209ms/step - loss: 1.9265 - box_loss: 1.2879 - class_loss: 0.6387 - val_loss: 2.4988 - val_box_loss: 1.5128 - val_class_loss: 0.9860 - lr: 1.0000e-05\n",
      "Epoch 35/50\n",
      "1912/1912 [==============================] - 403s 210ms/step - loss: 1.9313 - box_loss: 1.2859 - class_loss: 0.6455 - val_loss: 2.4805 - val_box_loss: 1.5033 - val_class_loss: 0.9772 - lr: 1.0000e-05\n",
      "Epoch 36/50\n",
      "1912/1912 [==============================] - ETA: 0s - loss: 2.0014 - box_loss: 1.3000 - class_loss: 0.7014"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 22:03:49.934180: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 9830528 bytes after encountering the first element of size 9830528 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1912/1912 [==============================] - 403s 211ms/step - loss: 2.0014 - box_loss: 1.3000 - class_loss: 0.7014 - val_loss: 2.4447 - val_box_loss: 1.5071 - val_class_loss: 0.9376 - lr: 1.0000e-06\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 22:04:17.760628: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 9830528 bytes after encountering the first element of size 9830528 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1912/1912 [==============================] - ETA: 0s - loss: 1.9772 - box_loss: 1.2979 - class_loss: 0.6793WARNING:tensorflow:Found duplicated `Variable`s in Model's `weights`. This is usually caused by `Variable`s being shared by Layers in the Model. These `Variable`s will be treated as separate `Variable`s when the Model is restored. To avoid this, please save with `save_format=\"tf\"`.\n",
      "1912/1912 [==============================] - 405s 211ms/step - loss: 1.9772 - box_loss: 1.2979 - class_loss: 0.6793 - val_loss: 2.4090 - val_box_loss: 1.4806 - val_class_loss: 0.9284 - lr: 1.0000e-06\n",
      "Epoch 38/50\n",
      "1912/1912 [==============================] - ETA: 0s - loss: 1.9585 - box_loss: 1.2864 - class_loss: 0.6722WARNING:tensorflow:Found duplicated `Variable`s in Model's `weights`. This is usually caused by `Variable`s being shared by Layers in the Model. These `Variable`s will be treated as separate `Variable`s when the Model is restored. To avoid this, please save with `save_format=\"tf\"`.\n",
      "1912/1912 [==============================] - 405s 211ms/step - loss: 1.9585 - box_loss: 1.2864 - class_loss: 0.6722 - val_loss: 2.3778 - val_box_loss: 1.4840 - val_class_loss: 0.8938 - lr: 1.0000e-06\n",
      "Epoch 39/50\n",
      "1912/1912 [==============================] - ETA: 0s - loss: 1.9412 - box_loss: 1.2743 - class_loss: 0.6669WARNING:tensorflow:Found duplicated `Variable`s in Model's `weights`. This is usually caused by `Variable`s being shared by Layers in the Model. These `Variable`s will be treated as separate `Variable`s when the Model is restored. To avoid this, please save with `save_format=\"tf\"`.\n",
      "1912/1912 [==============================] - 403s 210ms/step - loss: 1.9412 - box_loss: 1.2743 - class_loss: 0.6669 - val_loss: 2.3374 - val_box_loss: 1.4794 - val_class_loss: 0.8580 - lr: 1.0000e-06\n",
      "Epoch 40/50\n",
      "1912/1912 [==============================] - ETA: 0s - loss: 1.9325 - box_loss: 1.2732 - class_loss: 0.6593WARNING:tensorflow:Found duplicated `Variable`s in Model's `weights`. This is usually caused by `Variable`s being shared by Layers in the Model. These `Variable`s will be treated as separate `Variable`s when the Model is restored. To avoid this, please save with `save_format=\"tf\"`.\n",
      "1912/1912 [==============================] - 403s 211ms/step - loss: 1.9325 - box_loss: 1.2732 - class_loss: 0.6593 - val_loss: 2.3227 - val_box_loss: 1.4656 - val_class_loss: 0.8571 - lr: 1.0000e-06\n",
      "Epoch 41/50\n",
      "1912/1912 [==============================] - 402s 210ms/step - loss: 1.9507 - box_loss: 1.2908 - class_loss: 0.6599 - val_loss: 2.3337 - val_box_loss: 1.5000 - val_class_loss: 0.8338 - lr: 1.0000e-06\n",
      "Epoch 42/50\n",
      "1912/1912 [==============================] - ETA: 0s - loss: 1.9409 - box_loss: 1.2863 - class_loss: 0.6546WARNING:tensorflow:Found duplicated `Variable`s in Model's `weights`. This is usually caused by `Variable`s being shared by Layers in the Model. These `Variable`s will be treated as separate `Variable`s when the Model is restored. To avoid this, please save with `save_format=\"tf\"`.\n",
      "1912/1912 [==============================] - 402s 210ms/step - loss: 1.9409 - box_loss: 1.2863 - class_loss: 0.6546 - val_loss: 2.3133 - val_box_loss: 1.4728 - val_class_loss: 0.8405 - lr: 1.0000e-06\n",
      "Epoch 43/50\n",
      "1912/1912 [==============================] - 400s 209ms/step - loss: 1.9394 - box_loss: 1.2830 - class_loss: 0.6564 - val_loss: 2.3365 - val_box_loss: 1.4805 - val_class_loss: 0.8561 - lr: 1.0000e-06\n",
      "Epoch 44/50\n",
      "1912/1912 [==============================] - 402s 210ms/step - loss: 1.9443 - box_loss: 1.2907 - class_loss: 0.6536 - val_loss: 2.3186 - val_box_loss: 1.4899 - val_class_loss: 0.8287 - lr: 1.0000e-06\n",
      "Epoch 45/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 22:58:02.651964: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 9830528 bytes after encountering the first element of size 9830528 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1912/1912 [==============================] - ETA: 0s - loss: 1.9381 - box_loss: 1.2826 - class_loss: 0.6555WARNING:tensorflow:Found duplicated `Variable`s in Model's `weights`. This is usually caused by `Variable`s being shared by Layers in the Model. These `Variable`s will be treated as separate `Variable`s when the Model is restored. To avoid this, please save with `save_format=\"tf\"`.\n",
      "1912/1912 [==============================] - 404s 211ms/step - loss: 1.9381 - box_loss: 1.2826 - class_loss: 0.6555 - val_loss: 2.3070 - val_box_loss: 1.4758 - val_class_loss: 0.8312 - lr: 1.0000e-06\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 23:04:47.208144: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 9830528 bytes after encountering the first element of size 9830528 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1912/1912 [==============================] - 403s 211ms/step - loss: 1.9397 - box_loss: 1.2880 - class_loss: 0.6517 - val_loss: 2.3356 - val_box_loss: 1.4896 - val_class_loss: 0.8460 - lr: 1.0000e-06\n",
      "Epoch 47/50\n",
      "1912/1912 [==============================] - 403s 211ms/step - loss: 1.9437 - box_loss: 1.2913 - class_loss: 0.6523 - val_loss: 2.3269 - val_box_loss: 1.4811 - val_class_loss: 0.8459 - lr: 1.0000e-06\n",
      "Epoch 48/50\n",
      "1912/1912 [==============================] - 396s 207ms/step - loss: 1.9296 - box_loss: 1.2764 - class_loss: 0.6532 - val_loss: 2.3385 - val_box_loss: 1.4892 - val_class_loss: 0.8492 - lr: 1.0000e-06\n",
      "Epoch 49/50\n",
      "1912/1912 [==============================] - ETA: 0s - loss: 1.9391 - box_loss: 1.2837 - class_loss: 0.6554WARNING:tensorflow:Found duplicated `Variable`s in Model's `weights`. This is usually caused by `Variable`s being shared by Layers in the Model. These `Variable`s will be treated as separate `Variable`s when the Model is restored. To avoid this, please save with `save_format=\"tf\"`.\n",
      "1912/1912 [==============================] - 416s 217ms/step - loss: 1.9391 - box_loss: 1.2837 - class_loss: 0.6554 - val_loss: 2.3010 - val_box_loss: 1.4757 - val_class_loss: 0.8253 - lr: 1.0000e-06\n",
      "Epoch 50/50\n",
      "1912/1912 [==============================] - 398s 208ms/step - loss: 1.9266 - box_loss: 1.2781 - class_loss: 0.6486 - val_loss: 2.3434 - val_box_loss: 1.5007 - val_class_loss: 0.8427 - lr: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "# definizione di due callback per migliorare l'addestramento\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=5)\n",
    "\n",
    "history = yolo.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCH,\n",
    "    callbacks=[EvaluateCOCOMetricsCallback(val_ds, \"model-s-onlyhead\"), early_stopping, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGdCAYAAACyzRGfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAACTBklEQVR4nOzdd3wUdf7H8dds303vhQQIEDoiKqigKEURFLCAp2LBfnbP0/Pn3enp2TkLltNT7+yIFazYFUUQEAVEek8gFZLsJpvtM78/ZneTUBNIAffzfDzGmZ2dnfnuumTe+/1+5zuKpmkaQgghhBDtxNDRBRBCCCFEbJHwIYQQQoh2JeFDCCGEEO1KwocQQggh2pWEDyGEEEK0KwkfQgghhGhXEj6EEEII0a4kfAghhBCiXZk6ugC7UlWVkpISEhISUBSlo4sjhBBCiGbQNI3a2lpyc3MxGPZdt3HIhY+SkhLy8/M7uhhCCCGEOADFxcXk5eXtc5tDLnwkJCQAeuETExM7uDRCCCGEaA6Xy0V+fn70PL4vh1z4iDS1JCYmSvgQQgghDjPN6TIhHU6FEEII0a4kfAghhBCiXUn4EEIIIUS7OuT6fAghhGhboVCIQCDQ0cUQhyGz2YzRaDzo/Uj4EEKIGFJXV8e2bdvQNK2jiyIOQ4qikJeXR3x8/EHtR8KHEELEiFAoxLZt23A4HGRkZMhAjqJFNE2jsrKSbdu2UVhYeFA1IBI+hBAiRgQCATRNIyMjA7vd3tHFEYehjIwMtmzZQiAQOKjwIR1OhRAixkiNhzhQrfXdkfAhhBBCiHYl4UMIIYQQ7UrChxBCCCHalYQPIYQQh7SpU6dy5plndnQxRCuKmatdKmq9PPfdJkxGhTvG9uno4gghhBAxK2ZqPmq9Qf73w2beWFTU0UURQohDgqZp1PuDHTK11iBn3333HUOGDMFqtZKTk8P//d//EQwGo8+/++67DBgwALvdTlpaGqNHj8btdgMwd+5chgwZQlxcHMnJyQwbNoytW7e2SrnEvsVMzYfNrF+P7AuoHVwSIYQ4NHgCIfre9XmHHHvVP8fgsBzcKWj79u2MGzeOqVOn8uqrr7JmzRquvPJKbDYbd999N6WlpZx//vlMmzaNs846i9raWubNm4emaQSDQc4880yuvPJKZs6cid/vZ/HixXIZcjuJnfBh0it5/CGVkKphNMgXTAghDmfPPPMM+fn5PP300yiKQu/evSkpKeH222/nrrvuorS0lGAwyNlnn02XLl0AGDBgAABVVVU4nU7OOOMMunfvDkCfPtIk315iJ3yYG0Zi8wVDB524hRDicGc3G1n1zzEdduyDtXr1ao4//vgmtRXDhg2L3r9m4MCBjBo1igEDBjBmzBhOPfVUJk2aREpKCqmpqUydOpUxY8ZwyimnMHr0aM4991xycnIOulxi/2Kmz0fj8OGVphchhEBRFBwWU4dM7dG8YTQa+fLLL/n000/p27cvTz31FL169WLz5s0AvPTSS/z4448MHTqUt956i549e7Jw4cI2L5eIofBhNCiYjfqX3RsIdXBphBBCHKw+ffrw448/Num8On/+fBISEsjLywP0gDVs2DDuueceli5disViYfbs2dHtBw0axB133MGCBQvo378/b7zxRru/j1gUU20PNpORQCgo4UMIIQ4zTqeTZcuWNVl31VVXMX36dG644Qauv/561q5dyz/+8Q9uueUWDAYDixYt4uuvv+bUU08lMzOTRYsWUVlZSZ8+fdi8eTPPP/88EyZMIDc3l7Vr17J+/XouvvjijnmDMSa2wofFSK0vKM0uQghxmJk7dy6DBg1qsu7yyy9nzpw53HbbbQwcOJDU1FQuv/xy/v73vwOQmJjI999/z/Tp03G5XHTp0oVHH32UsWPHUl5ezpo1a3jllVfYuXMnOTk5XHfddVx99dUd8fZiTmyFD7PeyuQNSs2HEEIcLl5++WVefvnlvT6/ePHiPa7v06cPn3322R6fy8rKatL8ItpXzPT5AL3ZBaTPhxBCCNGRYit8yEBjQgghRIeLsfARbnaRmg8hhBCiw8RY+Ag3u0ifDyGEEKLDxFT4sEb7fEizixBCCNFRYip8SLOLEEII0fFiLHxIzYcQQgjR0WIsfEjNhxBCCNHRYit8mKTDqRBCCNHRYit8RJpd/BI+hBDicHHyySdz8803d8ix7777bo488sgOOfbvWYyFj0izi/T5EEIIITpKjIUPaXYRQgghOlqLw8f333/P+PHjyc3NRVEU3n///SbPa5rGXXfdRU5ODna7ndGjR7N+/frWKu9BsZrl3i5CCBGlaeB3d8ykaS0qajAY5PrrrycpKYn09HTuvPNOtPA+qqurufjii0lJScHhcDB27NjoeaeyspLs7GweeOCB6L4WLFiAxWLh66+/bvFHpqoq//znP8nLy8NqtXLkkUc2uXmd3+/n+uuvJycnB5vNRpcuXXjwwQfDH7fG3XffTefOnbFareTm5nLjjTe2uAy/By2+q63b7WbgwIFcdtllnH322bs9P23aNJ588kleeeUVCgoKuPPOOxkzZgyrVq3CZrO1SqEPlM0kzS5CCBEVqIcHcjvm2H8tAUtcszd/5ZVXuPzyy1m8eDFLlizhqquuonPnzlx55ZVMnTqV9evX8+GHH5KYmMjtt9/OuHHjWLVqFRkZGbz44ouceeaZnHrqqfTq1YuLLrqI66+/nlGjRrW42E888QSPPvoozz33HIMGDeLFF19kwoQJrFy5ksLCQp588kk+/PBD3n77bTp37kxxcTHFxcUAvPfeezz++OO8+eab9OvXj7KyMpYvX97iMvwetDh8jB07lrFjx+7xOU3TmD59On//+9+ZOHEiAK+++ipZWVm8//77nHfeeQdX2oNkk5oPIYQ4LOXn5/P444+jKAq9evVixYoVPP7445x88sl8+OGHzJ8/n6FDhwIwY8YM8vPzef/995k8eTLjxo3jyiuvZMqUKRxzzDHExcVFayNa6pFHHuH222+Pns8efvhhvv32W6ZPn86///1vioqKKCws5IQTTkBRFLp06RJ9bVFREdnZ2YwePRqz2Uznzp0ZMmTIwX84h6EWh4992bx5M2VlZYwePTq6LikpiWOPPZYff/xxj+HD5/Ph8/mij10uV2sWqYmGPh9S8yGEEJgdeg1ERx27BY477jgURYk+Pv7443n00UdZtWoVJpOJY489NvpcWloavXr1YvXq1dF1jzzyCP379+edd97h559/xmq1trjILpeLkpIShg0b1mT9sGHDojUYU6dO5ZRTTqFXr16cdtppnHHGGZx66qkATJ48menTp9OtWzdOO+00xo0bx/jx4zGZWvVUfFho1Q6nZWVlAGRlZTVZn5WVFX1uVw8++CBJSUnRKT8/vzWL1ETkahef1HwIIQQoit700RFToyDRHjZu3EhJSQmqqrJly5Y2O85RRx3F5s2buffee/F4PJx77rlMmjQJ0Gtv1q5dyzPPPIPdbufaa69l+PDhBAKBNivPoarDr3a54447cDqd0SnSNtYWpNlFCCEOT4sWLWryeOHChRQWFtK3b1+CwWCT53fu3MnatWvp27cvoHcCvfDCC/nDH/7AvffeyxVXXEFFRUWLy5CYmEhubi7z589vsn7+/PnRY0W2+8Mf/sALL7zAW2+9xXvvvUdVVRUAdrud8ePH8+STTzJ37lx+/PFHVqxY0eKyHO5ata4nOzsbgPLycnJycqLry8vL9zpIi9VqPaDqrwNhk7vaCiHEYamoqIhbbrmFq6++ml9++YWnnnqKRx99lMLCQiZOnMiVV17Jc889R0JCAv/3f/9Hp06don0P//a3v+F0OnnyySeJj49nzpw5XHbZZXz88cctLsdtt93GP/7xD7p3786RRx7JSy+9xLJly5gxYwYAjz32GDk5OQwaNAiDwcA777xDdnY2ycnJvPzyy4RCIY499lgcDgevv/46dru9Sb+QWNGq4aOgoIDs7Gy+/vrraNhwuVwsWrSIa665pjUPdUCig4zJOB9CCHFYufjii/F4PAwZMgSj0chNN93EVVddBcBLL73ETTfdxBlnnIHf72f48OHMmTMHs9nM3LlzmT59Ot9++y2JiYkAvPbaawwcOJBnn322xeemG2+8EafTyZ///GcqKiro27cvH374IYWFhQAkJCQwbdo01q9fj9FoZPDgwcyZMweDwUBycjIPPfQQt9xyC6FQiAEDBvDRRx+RlpbWuh/WYUDRtJZdbF1XV8eGDRsAGDRoEI899hgjRowgNTWVzp078/DDD/PQQw81udT2119/bfalti6Xi6SkJJxOZ/SL0lqKq+o5cdq32MwG1ty75yt2hBDi98rr9bJ582YKCgo6fOgDcXja13eoJefvFtd8LFmyhBEjRkQf33LLLQBccsklvPzyy/zlL3/B7XZz1VVXUVNTwwknnMBnn312SHzRrY2GV9c0rUnPaSGEEEK0jxaHj5NPPpl9VZYoisI///lP/vnPfx5UwdpCpMMpgC+oNnkshBAi9vTr14+tW7fu8bnnnnuOKVOmtHOJYkNMXVwc6XAK4AtI+BBCiFg3Z86cvV7quuuwEaL1xFT4MBsVDAqomt7pNAlzRxdJCCFEB4rFK00OBR0+zkd7UhRFxvoQQgghOlhMhQ9oPNCYjPUhhBBCdISYCx92qfkQQgghOlTMhY+Gy20lfAghhBAdIebCR3SIdbmzrRBCCNEhYi98SM2HEEL8bmzZsgVFUVi2bFmHluPll18mOTm5Q8twOInB8CF9PoQQQoiOFLPhwydXuwghhBAdIgbDh9zZVgghADRNoz5Q3yFTC+9piqqqTJs2jR49emC1WuncuTP333//btuFQiEuv/xyCgoKsNvt9OrViyeeeKLJNnPnzmXIkCHExcWRnJzMsGHDokOsL1++nBEjRpCQkEBiYiJHH300S5YsOaDP99lnn6V79+5YLBZ69erFa6+9Fn1O0zTuvvtuOnfujNVqJTc3lxtvvDH6/DPPPENhYSE2m42srCwmTZp0QGU4VMXUCKfQqMOpNLsIIWKcJ+jh2DeO7ZBjL7pgEQ6zo9nb33HHHbzwwgs8/vjjnHDCCZSWlrJmzZrdtlNVlby8PN555x3S0tJYsGABV111FTk5OZx77rkEg0HOPPNMrrzySmbOnInf72fx4sXRG41OmTKFQYMG8eyzz2I0Glm2bBlmc8tHw549ezY33XQT06dPZ/To0Xz88cdceuml5OXlMWLECN577z0ef/xx3nzzTfr160dZWRnLly8H9Bu43njjjbz22msMHTqUqqoq5s2b1+IyHMpiLnxYZZAxIYQ4rNTW1vLEE0/w9NNPc8kllwDQvXt3TjjhBLZs2dJkW7PZzD333BN9XFBQwI8//sjbb7/Nueeei8vlwul0csYZZ9C9e3cA+vTpE92+qKiI2267jd69ewNQWFh4QGV+5JFHmDp1Ktdeey2g3wF+4cKFPPLII4wYMYKioiKys7MZPXo0ZrOZzp07M2TIkGgZ4uLiOOOMM0hISKBLly4MGjTogMpxqIq58CFXuwghhM5usrPogkUdduzmWr16NT6fj1GjRjVr+3//+9+8+OKLFBUV4fF48Pv9HHnkkQCkpqYydepUxowZwymnnMLo0aM599xzycnJAfSQcMUVV/Daa68xevRoJk+eHA0pLbF69WquuuqqJuuGDRsWbQKaPHky06dPp1u3bpx22mmMGzeO8ePHYzKZOOWUU+jSpUv0udNOO42zzjoLh6P5NUWHuhjs8yE1H0IIAfr9rhxmR4dMkWaO5rDbmx9U3nzzTW699VYuv/xyvvjiC5YtW8all16K3++PbvPSSy/x448/MnToUN566y169uzJwoULAbj77rtZuXIlp59+Ot988w19+/Zl9uzZzf9Qmyk/P5+1a9fyzDPPYLfbufbaaxk+fDiBQICEhAR++eUXZs6cSU5ODnfddRcDBw6kpqam1cvRUWIvfEQHGZOaDyGEOBwUFhZit9v5+uuv97vt/PnzGTp0KNdeey2DBg2iR48ebNy4cbftBg0axB133MGCBQvo378/b7zxRvS5nj178qc//YkvvviCs88+m5deeqnFZe7Tpw/z58/frWx9+/aNPrbb7YwfP54nn3ySuXPn8uOPP7JixQoATCYTo0ePZtq0afz6669s2bKFb775psXlOFRJs4sQQohDms1m4/bbb+cvf/kLFouFYcOGUVlZycqVK3driiksLOTVV1/l888/p6CggNdee42ffvqJgoICADZv3szzzz/PhAkTyM3NZe3ataxfv56LL74Yj8fDbbfdxqRJkygoKGDbtm389NNPnHPOOS0u82233ca5557LoEGDGD16NB999BGzZs3iq6++AvRByUKhEMceeywOh4PXX38du91Oly5d+Pjjj9m0aRPDhw8nJSWFOXPmoKoqvXr1OvgP8xARg+FDrnYRQojDzZ133onJZOKuu+6ipKSEnJwc/vjHP+623dVXX83SpUv5wx/+gKIonH/++Vx77bV8+umnADgcDtasWcMrr7zCzp07ycnJ4brrruPqq68mGAyyc+dOLr74YsrLy0lPT+fss89u0oG1uc4880yeeOIJHnnkEW666SYKCgp46aWXOPnkkwFITk7moYce4pZbbiEUCjFgwAA++ugj0tLSSE5OZtasWdx99914vV4KCwuZOXMm/fr1O6jP8FCiaC292LqNuVwukpKScDqdJCYmtvr+3/qpiNvfW8HI3pm8OHVwq+9fCCEOVV6vl82bN1NQUIDNZuvo4ojD0L6+Qy05f8denw+p+RBCCCE6VMyFD6sMMiaEEKKFxo4dS3x8/B6nBx54oKOLd9iJwT4fkQ6ncqmtEEKI5vnvf/+Lx+PZ43OpqantXJrDXwyGD7nUVgghRMt06tSpo4vwuxJzzS5yV1shhBCiY8Vg+JBxPoQQQoiOFHvhQzqcCiGEEB0q9sJHtM+HNLsIIYQQHSEGw4f+lkOqRiAkAUQIIYRobzEYPozRZWl6EUKI2NC1a1emT5/erG0VReH9999v0/LEupgLH1ZTw1uWsT6EEEKI9hdz4UNRlGgAkZoPIYQQov3FTPhw+py8vfZt3ln3TsNYHzLQmBAihmmahlpf3yFTS+5p+vzzz5Obm4uqNq2tnjhxIpdddhkbN25k4sSJZGVlER8fz+DBg6O3rm8NK1asYOTIkdjtdtLS0rjqqquoq6uLPj937lyGDBlCXFwcycnJDBs2jK1btwKwfPlyRowYQUJCAomJiRx99NEsWbKk1cp2uIqZEU53endy78J7SbAkYDP/E6dHml2EELFN83hYe9TRHXLsXr/8jOJwNGvbyZMnc8MNN/Dtt98yatQoAKqqqvjss8+YM2cOdXV1jBs3jvvvvx+r1cqrr77K+PHjWbt2LZ07dz6ocrrdbsaMGcPxxx/PTz/9REVFBVdccQXXX389L7/8MsFgkDPPPJMrr7ySmTNn4vf7Wbx4MYqiADBlyhQGDRrEs88+i9FoZNmyZZjN5oMq0+9BzIQPm1G/9a8v6CNe7mwrhBCHjZSUFMaOHcsbb7wRDR/vvvsu6enpjBgxAoPBwMCBA6Pb33vvvcyePZsPP/yQ66+//qCO/cYbb+D1enn11VeJi4sD4Omnn2b8+PE8/PDDmM1mnE4nZ5xxBt27dwegT58+0dcXFRVx22230bt3bwAKCwsPqjy/FzETPqxGKwB+1Y/NrCdSqfkQQsQyxW6n1y8/d9ixW2LKlClceeWVPPPMM1itVmbMmMF5552HwWCgrq6Ou+++m08++YTS0lKCwSAej4eioqKDLufq1asZOHBgNHgADBs2DFVVWbt2LcOHD2fq1KmMGTOGU045hdGjR3PuueeSk5MDwC233MIVV1zBa6+9xujRo5k8eXI0pMSymOnzYTPZossWs97WKDUfQohYpigKBoejQ6ZIs0RzjR8/Hk3T+OSTTyguLmbevHlMmTIFgFtvvZXZs2fzwAMPMG/ePJYtW8aAAQPw+/1t8bHt5qWXXuLHH39k6NChvPXWW/Ts2ZOFCxcCcPfdd7Ny5UpOP/10vvnmG/r27cvs2bPbpVyHspgJH5GaDwCLKQjInW2FEOJwYbPZOPvss5kxYwYzZ86kV69eHHXUUQDMnz+fqVOnctZZZzFgwACys7PZsmVLqxy3T58+LF++HLfbHV03f/58DAYDvXr1iq4bNGgQd9xxBwsWLKB///688cYb0ed69uzJn/70J7744gvOPvtsXnrppVYp2+EsZsKHyWDCZNBbmSxmPXRIs4sQQhw+pkyZwieffMKLL74YrfUAvR/FrFmzWLZsGcuXL+eCCy7Y7cqYgzmmzWbjkksu4bfffuPbb7/lhhtu4KKLLiIrK4vNmzdzxx138OOPP7J161a++OIL1q9fT58+ffB4PFx//fXMnTuXrVu3Mn/+fH766acmfUJiVcz0+QC902mdWofZFAQUaXYRQojDyMiRI0lNTWXt2rVccMEF0fWPPfYYl112GUOHDiU9PZ3bb78dl8vVKsd0OBx8/vnn3HTTTQwePBiHw8E555zDY489Fn1+zZo1vPLKK+zcuZOcnByuu+46rr76aoLBIDt37uTiiy+mvLyc9PR0zj77bO65555WKdvhLKbCh9VopS5Qh8kUAkwSPoQQ4jBiMBgoKSnZbX3Xrl355ptvmqy77rrrmjxuSTPMrmOQDBgwYLf9R2RlZe21D4fFYmHmzJnNPm4siZlmF2jodGoy6n0+fHJnWyGEEKLdxVT4iHQ6jYQPqfkQQojYMmPGDOLj4/c49evXr6OLFzNirtkFwCDhQwghYtKECRM49thj9/icjDzafmIqfESaXRrChzS7CCFELElISCAhIaGjixHzYqrZJTLEusEQAKTmQwghhOgIMRU+rCa92UUxRAYZk5oPIYQQor3FVPiI1HygSJ8PIYQQoqPEVPiIDrFu0Mf7l/AhhBBCtL+YCh+RDqca0udDCCGE6CgxFT4iNR+aEqn5kD4fQggRC7p27cr06dObta2iKLz//vttWp59Ofnkk7n55ps77PjtISbDhyo1H0IIIUSHianwEWl2UbVwzUdQwocQQgjR3mIrfISvdgkhzS5CCHG4eP7558nNzUVVm/7NnjhxIpdddhkbN25k4sSJZGVlER8fz+DBg/nqq68O6pilpaWMHTsWu91Ot27dePfdd5s8v2LFCkaOHIndbictLY2rrrqKuro6AObOnYvFYmHevHnR7adNm0ZmZibl5eUtLkt1dTUXX3wxKSkpOBwOxo4dy/r166PPb926lfHjx5OSkkJcXBz9+vVjzpw50ddOmTKFjIwM7HY7hYWFvPTSSwfykbSq2Aof4ZqPkCZXuwghhKZpBHyhDpl2vXPsvkyePJmdO3fy7bffRtdVVVXx2WefMWXKFOrq6hg3bhxff/01S5cu5bTTTmP8+PEUFRUd8Gdz5513cs4557B8+XKmTJnCeeedx+rVqwFwu92MGTOGlJQUfvrpJ9555x2++uorrr/+eqChz8ZFF12E0+lk6dKl3Hnnnfz3v/8lKyurxWWZOnUqS5Ys4cMPP+THH39E0zTGjRtHIKB3Ibjuuuvw+Xx8//33rFixgocffpj4+Pjo+1i1ahWffvopq1ev5tlnnyU9Pf2AP5fWElPDq0f6fATD4cMnNR9CiBgW9Ks8f9N3HXLsq544CbPV2KxtU1JSGDt2LG+88QajRo0C4N133yU9PZ0RI0ZgMBgYOHBgdPt7772X2bNn8+GHH0YDQUtNnjyZK664Irq/L7/8kqeeeopnnnmGN954A6/Xy6uvvkpcXBwATz/9NOPHj+fhhx8mKyuL++67jy+//JKrrrqK3377jUsuuYQJEya0uBzr16/nww8/ZP78+QwdOhTQb46Xn5/P+++/z+TJkykqKuKcc85hwIABAHTr1i36+qKiIgYNGsQxxxwD6B1vDwWtXvMRCoW48847KSgowG630717d+69994Wpdy2EhnhNKD6APCHVEJqx5dLCCHEvk2ZMoX33nsPn0//+z1jxgzOO+88DAYDdXV13HrrrfTp04fk5GTi4+NZvXr1QdV8HH/88bs9jtR8rF69moEDB0aDB8CwYcNQVZW1a9cCYLFYmDFjBu+99x5er5fHH3/8gMqxevVqTCZTk5vhpaWl0atXr2h5brzxRu677z6GDRvGP/7xD3799dfottdccw1vvvkmRx55JH/5y19YsGDBAZWjtbV6zcfDDz/Ms88+yyuvvEK/fv1YsmQJl156KUlJSdx4442tfbgWifT5iIQPAF8whMMSUxVAQggBgMli4KonTuqwY7fE+PHj0TSNTz75hMGDBzNv3rzoCf3WW2/lyy+/5JFHHqFHjx7Y7XYmTZqE3+9vi6I3W+REX1VVRVVVVZOw0pquuOIKxowZwyeffMIXX3zBgw8+yKOPPsoNN9zA2LFj2bp1K3PmzOHLL79k1KhRXHfddTzyyCNtUpbmavWajwULFjBx4kROP/10unbtyqRJkzj11FNZvHhxax+qxSLNLv5G4UM6nQohYpWiKJitxg6ZFEVpUVltNhtnn302M2bMYObMmfTq1YujjjoKgPnz5zN16lTOOussBgwYQHZ2Nlu2bDmoz2bhwoW7Pe7Tpw8Affr0Yfny5bjd7ujz8+fPx2Aw0KtXLwA2btzIn/70J1544QWOPfZYLrnkkt06zDZHnz59CAaDLFq0KLpu586drF27lr59+0bX5efn88c//pFZs2bx5z//mRdeeCH6XEZGBpdccgmvv/4606dP5/nnn29xOVpbq4ePoUOH8vXXX7Nu3ToAli9fzg8//MDYsWP3uL3P58PlcjWZ2kqkw6kv5MNs1L/40ulUCCEOD1OmTOGTTz7hxRdfZMqUKdH1hYWFzJo1i2XLlrF8+XIuuOCCAzrRN/bOO+/w4osvsm7dOv7xj3+wePHiaP+RKVOmYLPZuOSSS/jtt9/49ttvueGGG7jooovIysoiFApx4YUXMmbMGC699FJeeuklfv31Vx599NEWl6OwsJCJEydy5ZVX8sMPP7B8+XIuvPBCOnXqxMSJEwG4+eab+fzzz9m8eTO//PIL3377bTQo3XXXXXzwwQds2LCBlStX8vHHH0ef60itHj7+7//+j/POO4/evXtjNpsZNGgQN998c5MvSmMPPvggSUlJ0Sk/P7+1ixQVaXbxBX3YTHpHJwkfQghxeBg5ciSpqamsXbuWCy64ILr+scceIyUlhaFDhzJ+/HjGjBkTrRU5UPfccw9vvvkmRxxxBK+++iozZ86M1jQ4HA4+//xzqqqqGDx4MJMmTWLUqFE8/fTTANx///1s3bqV5557DoCcnByef/55/v73v7N8+fIWl+Wll17i6KOP5owzzuD4449H0zTmzJmD2WwG9L6W1113HX369OG0006jZ8+ePPPMM4De9+SOO+7giCOOYPjw4RiNRt58882D+mxag6K1ck/QN998k9tuu41//etf9OvXj2XLlnHzzTfz2GOPcckll+y2vc/ni3YgAnC5XOTn5+N0OklMTGzNorHJuYmJ708k0ZKIb+M97KjzMefGE+mb27rHEUKIQ5HX62Xz5s0UFBRgs9k6ujjiMLSv75DL5SIpKalZ5+9W72l52223RWs/AAYMGMDWrVt58MEH9xg+rFYrVqu1tYuxR9Gaj5APm1mv9JFRToUQQoj21erNLvX19RgMTXdrNBoPuv2tNUQ6nPpCPqyR8CHNLkIIETNmzJhBfHz8Hqd+/fq1+fGLior2evz4+PiDujz4cNLqNR/jx4/n/vvvp3PnzvTr14+lS5fy2GOPcdlll7X2oVos0uEUwGbWw5AMNCaEELFjwoQJTcbMaCzSh6It5ebmsmzZsn0+HwtaPXw89dRT3HnnnVx77bVUVFSQm5vL1VdfzV133dXah2qxSM0HgNUcBKTmQwghYklCQgIJCQkddnyTyUSPHj067PiHilYPHwkJCUyfPp3p06e39q4PmslgwqSYCGpBzGY9dEifDyGEEKJ9xdSN5aBhiHWzKRw+pNlFCCGEaFcxFz4iV7yYTNLsIoQQQnSE2Asf4U6nJqPUfAghhBAdIebCR6TTqdR8CCGEEB0jZsOH0RAOH9LhVAghfve6du3aKhdCvPzyyyQnJx/0fg7W1KlTOfPMMzu6GAcs5sJHpNnFYNTDh4zzIYQQQrSvmAsfkZoPxRAApNlFCCGEaG8xFz4iV7sYDNLnQwghDgfPP/88ubm5u92mY+LEiVx22WVs3LiRiRMnkpWVRXx8PIMHD+arr7464OPV1NRw9dVXk5WVhc1mo3///nz88cd73LY5x37mmWcoLCzEZrORlZXFpEmTos+9++67DBgwALvdTlpaGqNHj8btdre4zD6fjxtvvJHMzExsNhsnnHACP/30U/T56upqpkyZQkZGBna7ncLCQl566SUA/H4/119/PTk5OdhsNrp06cKDDz7Y4jK0RKsPMnaoi4zzQbTmQ5pdhBCxSdM0go3uKt6eTFYriqI0a9vJkydzww038O233zJq1CgAqqqq+Oyzz5gzZw51dXWMGzeO+++/H6vVyquvvsr48eNZu3YtnTt3blG5VFVl7Nix1NbW8vrrr9O9e3dWrVqF0Wjc4/b7O/aSJUu48cYbee211xg6dChVVVXMmzcPgNLSUs4//3ymTZvGWWedRW1tLfPmzeNAbjb/l7/8hffee49XXnmFLl26MG3aNMaMGcOGDRtITU3lzjvvZNWqVXz66aekp6ezYcMGPB4PAE8++SQffvghb7/9Np07d6a4uJji4uIWl6ElYi58RGo+IBw+pMOpECJGBX0+nrxk0v43bAM3vvIu5l1uyb43KSkpjB07ljfeeCMaPt59913S09MZMWIEBoOBgQMHRre/9957mT17Nh9++CHXX399i8r11VdfsXjxYlavXk3Pnj0B6Nat2163Hzhw4D6PXVRURFxcHGeccQYJCQl06dKFQYMGAXr4CAaDnH322XTp0gXQ7wTfUm63m2effZaXX36ZsWPHAvDCCy/w5Zdf8r///Y/bbruNoqIiBg0axDHHHAPoHXAjioqKKCws5IQTTkBRlGhZ2lLsNbuEO5xqivT5EEKIw8WUKVN477338IVrambMmMF5552HwWCgrq6OW2+9lT59+pCcnEx8fDyrV68+oDvELlu2jLy8vGjw2J/9HfuUU06hS5cudOvWjYsuuogZM2ZQX18P6MFl1KhRDBgwgMmTJ/PCCy9QXV3d4jJv3LiRQCDAsGHDouvMZjNDhgxh9erVAFxzzTW8+eabHHnkkfzlL39hwYIF0W2nTp3KsmXL6NWrFzfeeCNffPFFi8vQUjFX8xHpcNoQPqTZRQgRm0xWKze+8m6HHbslxo8fj6ZpfPLJJwwePJh58+bx+OOPA3Drrbfy5Zdf8sgjj9CjRw/sdjuTJk3C7/e3uFx2u71F2+/v2AkJCfzyyy/MnTuXL774grvuuou7776bn376ieTkZL788ksWLFjAF198wVNPPcXf/vY3Fi1aREFBQYvLvi9jx45l69atzJkzhy+//JJRo0Zx3XXX8cgjj3DUUUexefNmPv30U7766ivOPfdcRo8ezbvvtt13I+ZqPqLhA/2LITUfQohYpSgKZputQ6bm9veIsNlsnH322cyYMYOZM2fSq1cvjjrqKADmz5/P1KlTOeussxgwYADZ2dls2bLlgD6TI444gm3btrFu3bpmbd+cY5tMJkaPHs20adP49ddf2bJlC9988w2g/z8YNmwY99xzD0uXLsVisTB79uwWlbl79+5YLBbmz58fXRcIBPjpp5/o27dvdF1GRgaXXHIJr7/+OtOnT+f555+PPpeYmMgf/vAHXnjhBd566y3ee+89qqqqWlSOloi5mo9Is4sq4UMIIQ4rU6ZM4YwzzmDlypVceOGF0fWFhYXMmjWL8ePHoygKd955525XxjTXSSedxPDhwznnnHN47LHH6NGjB2vWrEFRFE477bTdtt/fsT/++GM2bdrE8OHDSUlJYc6cOaiqSq9evVi0aBFff/01p556KpmZmSxatIjKykr69OnTojLHxcVxzTXXcNttt5Gamkrnzp2ZNm0a9fX1XH755QDcddddHH300fTr1w+fz8fHH38cPc5jjz1GTk4OgwYNwmAw8M4775Cdnd2mg6nFXPiI1HwEtUj4kGYXIYQ4HIwcOZLU1FTWrl3LBRdcEF3/2GOPcdlllzF06FDS09O5/fbbcblcB3yc9957j1tvvZXzzz8ft9tNjx49eOihh/a47f6OnZyczKxZs7j77rvxer0UFhYyc+ZM+vXrx+rVq/n++++ZPn06LpeLLl268Oijj0Y7jbbEQw89hKqqXHTRRdTW1nLMMcfw+eefk5KSAoDFYuGOO+5gy5Yt2O12TjzxRN58801AbxqaNm0a69evx2g0MnjwYObMmYPB0HaNI4p2INf0tCGXy0VSUhJOp5PExMRW3/9ba97ivkX3cWzWSXw1dyzJDjPL7jq11Y8jhBCHGq/Xy+bNmykoKMDWzCtNhGhsX9+hlpy/Y6/PR3icj6AqzS5CCCFER4i58BHp8xHU9Mu1vAH1gAZ0EUIIcfiZMWMG8fHxe5z69evX0cWL2lsZ4+Pjo4OUHc5irs9HZJCxgNpwCZYvqGIz73n0OiGEEL8fEyZM4Nhjj93jc2azuZ1Ls3fLli3b63OdOnVqv4K0kZgLH5EOp361YUhhX0DChxBCxIKEhAQSEhI6uhj71aNHj44uQpuK2WYXf8iHIXyZuQyxLoSIJdLULA5Ua313Yi58RGo+vCFvtLZDOp0KIWJB5OZoBzLypxDQ8N3Z2432mivmml0ifT68QT181PtDMtaHECImmEwmHA4HlZWVmM3mNh3HQfz+qKpKZWUlDocDk+ng4kPMhY/Ipba+kA+bSf+HJzUfQohYoCgKOTk5bN68ma1bt3Z0ccRhyGAw0Llz5xYPj7+r2AsfxobwkWCW8CGEiC0Wi4XCwkJpehEHxGKxtEqNWcyFD7up4Y6FVrPe3OINSrOLECJ2GAwGGeFUdKiYa/CL1HwAWMx6jYfUfAghhBDtJ+bCh8lgwqToFT5WCR9CCCFEu4u58AENnU7N4fDhk6tdhBBCiHYTm+Ej3PRiNgUBGWRMCCGEaE8xGT4iY32YjOHwIc0uQgghRLuJyfARaXYxGCN9PqTZRQghhGgvMRk+IjUfRmMAkJoPIYQQoj3FZvgwRcKH1HwIIYQQ7S0mw0ekw6nBEK75kA6nQgghRLuJyfARaXZRDNLhVAghhGhvMRk+Ih1OlXDNh4zzIYQQQrSf2AwfkSHWFelwKoQQQrS3mAwfkWYXTdHv6ih9PoQQQoj2E5PhI9LsohGp+ZBmFyGEEKK9xGT4aKj5kGYXIYQQor3FZvgIj/OhEm52kfAhhBBCtJuYDB+RDqchLRI+pNlFCCGEaC8xGT4izS6R8OGTDqdCCCFEu4nJ8BHpcBqUmg8hhBCi3cVk+IjUfETCh0f6fAghhBDtJibDR6TPh1/1AhBSNQIhqf0QQggh2kNsho9ws0tA9UfXyRUvQgghRPuIyfARaXbxh3zRddLvQwghhGgfsRk+wuN8eENerCb9I5CaDyGEEKJ9xGb4CNd8+EI+bGajviyX2wohhBDtIibDR6TPhy/ow2aO1HxIs4sQQgjRHmIzfISvdvGGvFjN0uwihBBCtKeYDB+RZhcAm0kDpOZDCCGEaC8xGT4izS4AFnMQkJoPIYQQor20SfjYvn07F154IWlpadjtdgYMGMCSJUva4lAHxGwwY1T0jqZmsx46vNLhVAghhGgXptbeYXV1NcOGDWPEiBF8+umnZGRksH79elJSUlr7UAfFZrLhDrixmEOAQZpdhBBCiHbS6uHj4YcfJj8/n5deeim6rqCgoLUPc9CsRivugBuzKQhYpNlFCCGEaCet3uzy4YcfcswxxzB58mQyMzMZNGgQL7zwwl639/l8uFyuJlN7iHQ6NZvCzS4SPoQQQoh20erhY9OmTTz77LMUFhby+eefc80113DjjTfyyiuv7HH7Bx98kKSkpOiUn5/f2kXao0inU6NRDx2+oDS7CCGEEO2h1cOHqqocddRRPPDAAwwaNIirrrqKK6+8kv/85z973P6OO+7A6XRGp+Li4tYu0h5Faj6MxgAgNR9CCCFEe2n18JGTk0Pfvn2brOvTpw9FRUV73N5qtZKYmNhkag+RgcYiNR8SPoQQQoj20erhY9iwYaxdu7bJunXr1tGlS5fWPtRBiTS7KIZIzYc0uwghhBDtodXDx5/+9CcWLlzIAw88wIYNG3jjjTd4/vnnue6661r7UAcl0uzSED6k5kMIIYRoD60ePgYPHszs2bOZOXMm/fv3595772X69OlMmTKltQ91UGymSPgIj3AqHU6FEEKIdtHq43wAnHHGGZxxxhltsetWE+nzoShS8yGEEEK0p5i8tws0NLtoEj6EEEKIdhWz4SN6c7lw+PBJh1MhhBCiXcRs+IjUfKj4AbmxnBBCCNFeYjZ8RPp8RMOHNLsIIYQQ7SJmw0fkapeQFgkf0uwihBBCtIeYDR+Rmo+Q1HwIIYQQ7Spmw0ek5iOoSfgQQggh2lPshg/jLuFDBhkTQggh2kXMho9Is0tA9QHgD6qoqtaRRRJCCCFiQuyGD1PT8AHgk9oPIYQQos3FbPiINLv4Q/7oOo/0+xBCCCHaXMyGj0jNhy/kxWxUAOl0KoQQQrSHmA0fkZoPb8iLzWTUlyV8CCGEEG0uZsNHpMOpL+jDao6ED+nzIYQQQrS1mA0fkXE+vCEvVnO42UXu7yKEEEK0udgNH+FmFwCbWb/EVppdhBBCiLYXs+Ej0uEUwGLWQ4dPml2EEEKINhez4cNsMGNU9L4e1nD4kJoPIYQQou3FbPiAhk6nZlM4fEifDyGEEKLNxXT4iHQ6NZuDgFztIoQQQrSHmA4fkZoPkzESPqTmQwghhGhrEj4AU6TZRWo+hBBCiDYX0+HDbrIDYJSaDyGEEKLdxHT4iNR8GA3h8CEdToUQQog2F9vhIzzWhyFc8yHjfAghhBBtL6bDR2SUU4MhAEizixBCCNEeYjp8RJpdFIP0+RBCCCHaS0yHj8g4H1q05kOaXYQQQoi2FtPhI1LzAX5AOpwKIYQQ7UHCB6Ap0udDCCGEaC8xFT5Unw//1q3Rx5FxPjSk2UUIIYRoLzETPup/+okNw09i281/QtM0oKHmQ1XCzS5S8yGEEEK0uZgJH9bCQlSPB9/q1XhXrgIaOpyqmh4+fEGp+RBCCCHaWsyED2NyMgmnnAJAzbvvAA01HyFN+nwIIYQQ7SVmwgdA8uTJALg++hi1vj4aPoL4AAkfQgghRHuIqfDhGDIYc+fOqG43rs8+jza7BNVInw9pdhFCCCHaWkyFD8VgIHnSJABq3n03WvMRUMM1H8FQtDOqEEIIIdpGTIUPgKQzJ4LRiOeXX3AUVwEN4UPTwB+S2g8hhBCiLcVc+DBnZhJ/8skAOD5fAIA/HD5Aml6EEEKIthZz4QMgebLe9GL6Yj6moIYv5MOg6M/5pNOpEEII0aZiMnzEn3ACpqwslBoXg9fr4cNmNgJS8yGEEEK0tZgMH4rJRNLZZwEwclnT8OGRmg8hhBCiTcVk+ABIPmcSKAoDt2gk7PBgNentLjLWhxBCCNG2YjZ8WPI6YT1uCAAjloewmfVLbCV8CCGEEG0rZsMHEB3z4+QVGjZTeIh1ub+LEEII0aZiOnwkjT4Flx3SamHA9pWA1HwIIYQQbS2mw4fRamXBQAsAx65aCEj4EEIIIdpaTIcPgIXHxAPQe9MaUrwufHKprRBCCNGmYj58VGfHsSYPDJrKKUU/4Q1KzYcQQgjRlmI+fFiNVr4eqH8MY7YuxusLdHCJhBBCiN+3mA8fNpONhb0VfFYrue6d2Ff/etD71AIB6pcupfrNt3B9+SXeNWsI1dW1QmmFEEKIw5+powvQ0axGKz6LwpqBfRi4eBnZ8z6Ha85p0T60QADPb79Rv/gn6hcvpn7pUrT6+t22M6akYM7Lw5KfhzkvH3NeJyydu+AYfAyK0dhab0kIIYQ4pMV8+LAZbQCsGtKPgYuXkbP8R4LV1ZhSUvb6GtXrxbt6dUPY+OUXNI+nyTbG5GRsAwYQcjoJFBcTqq6OTt4VK5psGz9yJHn/fhpFUVr/DQohhBCHGAkfJj187MhLZWNSLt2dJbg++pjUiy9CCwbxFxXhW7ce3/r1+Natw7d+Pf6iIlCbXhVjTE7GMXgwjiFDcAwZgrWwB4qhoVUrVFdHYNs2Atu24S/eRqC4GP/2bdQv+JG6b76h9vPPSTzttHZ970IIIURHiPnwYTVaAVCMQT7tcizX/zqbHc8/T82sWfg3bkQL7LkDqjE1Fccxx4TDxmCsPZqGjd22j4/H2Ls3tt69m6yvfOppdvz735Q/+BBxJ5yIMT6u9d6cEEIIcQhq8w6nDz30EIqicPPNN7f1oQ5IpOYDQ5C5eUcRMFsJ7diBb80atEAAxeHAdsQRJJ1zNpn/dzudX/wfhfO+p3D+D+Q9+QSpF07B1rPnPoPHvqRdeQXm/HyC5eXseOaZVnxnQgghxKGpTWs+fvrpJ5577jmOOOKItjzMQYnUfKD4cVvszJr0J67P9WPt3gNrz0LMubkHHCyaw2Czkf33v1F89R+pevVVks86E2thYYv3U/Puu/i3byf9mmswWCxtUFIhhBCidbTZWbWuro4pU6bwwgsvkLKPzpsdrSF86M0r6zv1Iv3KK0kYOQJLXl6bBo+I+JNOIn70KAgGKbvnn2ia1qLXV7/5JqV/v5Odz/6Hkj//GS0YbKOSCiGEEAevzc6s1113HaeffjqjR49uq0O0ikizi0r4rrYdNLx69h13oNhs1C9Zguujj5r9urrvv6fsn/fqDxSF2i+/ouT/7kALyUitQgghDk1tEj7efPNNfvnlFx588MH9buvz+XC5XE2m9hSp+dDwAx13Yzlzp06kX3MNAOXT/kWoGZ+Dd80att/8J1BVks46i7x/Pw0mE66PP6bs7rtbXIMihBBCtIdWDx/FxcXcdNNNzJgxA5vNtt/tH3zwQZKSkqJTfn5+axdpnyLjfIQ6OHwApF06FUtBAaEdO6h88ql9bhsoL6f46j+i1tfjOO44cu65m4SRI+n0r2lgMFDzzruUP/CgBBAhhBCHnFYPHz///DMVFRUcddRRmEwmTCYT3333HU8++SQmk4nQLs0Bd9xxB06nMzoVFxe3dpH2KdLsEtIi4aPj7mqrWCxk33UnANVvvIF31ao9bheqc1P8x2sIlpdj6d6dvCefQAl3Mk0cO5ac++/X9/Haa1Q+Pr1dyi6EEEI0V6uHj1GjRrFixQqWLVsWnY455himTJnCsmXLMO4yjLjVaiUxMbHJ1J4izS7BcPjwdfBdbeOOP57EcWNBVfXOp7sMZqYFg2z/8y34Vq/GmJZG/nP/wbjLZ5Z81plkhUPMzuefZ8d//tNu5RdCCCH2p9UvtU1ISKB///5N1sXFxZGWlrbb+kPBoVTzEZF5++3Uzf0Oz/LlOGfNInnSJAA0TaP8gQdwf/c9itVK/jP/xpKXt8d9pF5wAZrHS8W//kXl9CdQbDbSpk5tx3dx+NI0TYa6F0KINhTzd7WN1HwE1I7v8xFhzsoi/YYbAKh45FGC1dUAVL3yCtVvzARFIfdf07APHLjP/aRdfhnp11+v7+ehh6l+8609bqdpGoHyctwLFlD16mtUPPEEvg0bWvEdHT6CVVVsnjCBzZMm4127rqOLI4QQv0vtMrz63Llz2+MwByTS4TSg+gAIqhrBkIrJ2LG5LPXCKThnzcK3fj2Vj08n7sQTqHh4GgCZt91G4qmnNms/6dddi+b1sPO//6PsnntAUzHl5ODfuAnfxo34N27Et3Ejal1dk9dV/fd/pF93LWmXX45iNrf6+zsUaZpG6V134VuvB68tkyeTeftfSLngAqkJEUKIViT3djHpNR/+cPgA8AZV4js4fChmM9n/uIutF15EzTvv4PzgA9A0ks8/j9RLpzZ/P4pCxp//jOrxUj1jBmX3/HPPGxqNWDp3xtK9G2qdm/qFC6mc/gSuz78g9/77sPXt26Lyq14vtV9+RaCkBDRVH3ckpKKpjeaqBmoIc5cupJx7LoqpY7+OztnvU/fV12A24zjqKOoXLaL83vtw/zCfnAfu3+edjoUQQjRfzIePSM2HP9QofARCxFs7/qNxHHMMSRMn4vzgAzSfj7iThpP9t7+1+Fe4oihk/e2voKnUvP8Blvx8rN27YeneHWt4MnfpEh2WXdM0XB99RPn9D+BbvZrNk88l7YorSL/2GgxW6z6PFdi+neo336TmnXcJ1dQ0u4x133xLp8ce3a3zbHvxb9tGefgqoYwbbyDtiiuofu01Kv71CHXffsvmCRPJnfYwcccf3yHlE0KI3xNFO8QGgnC5XCQlJeF0OtvlypcN1Rs468OzSLYmU/HbX/EFVX64fQR5KY42P3ZzBHfsYPO552LOyCT/f/9r17veBnfsoOy++6n97DMALN26kXP/fTgGDWqynaZp1C9cSNWMGdR98y2Er9Ax5+biOO44FKMRDAYUowEMRjAoKAYjGA0QDFL91ttoXi+Wrl3Je+YZrN0K2u09AmihEFsvuQTPkp+xH300XV59RS8z4F29mu1/vhX/pk2gKKRdcTkZN94YM01RQgjRXC05f8d8+NhWu42xs8ZiN9nxbbgPpyfAV7ecRI/M+DY/dnNpmgaa1i73mdkT1xdfUPbPewnt2AGKQspFF5J5881oqobzww+onvEG/o0bo9vHDT2elClTiD/55OhJfF+8q1ZRfN31BEtLMSQk0Onxx4k/YVhbvqUmdv7vf1T86xEMDgcFH7yPZZeB7tT6esofepiat98GwDZgAJ0efQRL587tVkYhhDjUSfhogR2eHYx4ewQKCrbtj1Lh8vPxDSfQv1NSmx/7cBKqqaH8oYdxvv8+AKacHFSXC9XtBsDgcJB05pmkTLkAa/fuLd5/cMcOtt1wI56lS8FgIOv2v5By8cVt3tHTu3YtWyZNRgsEyLn/PpLPOWev27o+/4LSu+5CdToxOBykX3ct5pwcFJsNxWrFYLOhWG0Y7OG5zYohIWG/TVVCCPF7IOGjBWr9tQydORSAlIpHKdoZ4L1rjufoLqltfuzDUd28eZTe9Q+CpaUAWLp2JWXKFJLOOhNj/MHVFql+P2V334Nz1iwAks45m+x//CPaF2VPtGAQz9Kl1H79Db4NG0gcN46ks85sVmhR/X62TJqMb9064keOJO/fT+/3dYHSUkpu+wv1S5Y0702ZzSSfOZG0q67arUZFCCF+TyR8tEAgFOCo148CILv6X6wvC/H65cdyQmF6mx/7cBWqc+N8710s3XsQN/T4Vm0O0jSNqldeoWLav0BVsR91FHlPPYkpLS26jVpfT938+dR9/Q11c+fu1rE17sQTybnnbsy5ufs8Vvm//kXV/17EmJpKt48+bHKMfZYxFKLq1ddw/7gAzetD9Xn1udeD5vWheb2oPn0eZTSSdMYZpF19dbv3aRFCiPYg4aMFNE3jyNeORNVUOtc9xMpi+O/FxzC6b1abH1vsXd28eWz/0y2odXWYcnPIfeAB/EVF1H39De4ff0Tz+6PbGpKSSDj5JEyZWVS98gqa348hLo7M224j+Q/n7rE2w714MUWXTAVNI++Zf5MwcmSrvwdN0/AsXcqOZ/+De948faWikDj2NNKu/iO2Xj1b/ZhCCNFRJHy00JAZQ/AEPXT33c+yTUaevmAQZxyx71/Nou35Nm1i2zXX4t+6dbfnzHl5JIwaSfzIUTiOPio6Rohv0yZK//o3PMuWAeh3/L33n02aPEJ1dWyeMJFASQlJk84h97772vy9eFasYMd/nqPu66+j6+JHjyL9mmuw9+vX5scXQoi2JuGjhYa/OZxqXzW9Q//kp3UWHpk8kElH7/meKaJ9hZxOtv/5Vtw//IBtwIBw4BiJtbBwr/0ztFCI6tdfp+Lx6WheL4rdTuaf/kTKhVNQDAZK7vgrztmzMeflUfD+++16+bJ3zRp2/Oc5aj//HML/9OJOPBH7gAEYU1IwJifr85RkTOFlxW6XEVaFEIc8CR8tdMq7p1DmLmMAd7JgdRz3ndmfC4/r0i7HFvunaRqqu77FIcFfVETp3/5O/U8/AWA/6igSx5xK+YMPgaLQ5fXXcBx9dFsUeb98Gzey47nncH38SXRclL1RrFaMqamkXXYZqRdd2E4lFEKIlmnJ+bvjh/E8BERGOTWZ9JvKHQo3lxMNFEU5oNoJS+fOdH7lZWreeouKfz2C55df8PzyCwBpV1zeYcEDwNq9O52mTSPjuutwfvwxwR07CFXXEKqpIVRdHZ20QADN5yNYWkrF44+TNHFCh40CK4QQrUXCB2Az6eHDaAwC4Avu+5eoOHwoBgMp559P/PDhlN71D9zz52Pt0yd61+COZunShYzrrtvjc5qmodXXE6qpofiP1+Bbv56ad98j7bJL27mUQgjRujr27mmHCKtRHwQqEj6k5uP3x9ypE/n/fYGub71Jl9de2+fYIYcKRVEwxMVh7tSJ1EsuBqD69dfRgsEOLpkQQhwcCR80NLtI+Ph9UxQF+8CB7drBtLUknnEGxpQUAiUl1H79TUcXRwghDoqED8Bq0ms+lGj4kGYXcWgx2Gwkn/cHAKpefbWDSyOEEAdHwgcNzS4GQwCQmg9xaEo573wwmfD8/DOe31Z2dHGEEOKASfigodkFJVzzIR1OxSHInJVJ4tixAFS/JrUfQojDl4QPGppdUPQhu6XmQxyqUi/WO54653xKoKKig0sjhBAHRsIHDTUfmiLNLuLQZh/QH/tRR0EgQM2bb3Z0cYQQ4oBI+KBhnA8NPXz4pMOpOIRFaj+qZ76J6vN1cGmEEKLlJHzQ0OFUizS7BKXmQxy6EkaPwpSbQ6i6GtfHH3d0cYQQosUkfNDQ7KJq0udDHPoUk4nUKVMAqHr1NQ6x2zMJIcR+SfigocNpkEifD2l2EYe25EmTUOx2fGvXUr9ocUcXRwghWkTCBw01HyGp+RCHCWNSEslnnQnIoGNCiMOPhA8a+nwENb3znoQPcThIufAiAOq+/Rb/1q0dXBohhGg+CR80NLsE1HD4kEHGxGHA2q2AuJOGg6ZR9fqMji6OEEI0m4QPwG60AxBQ9WYXf1BFVaUTnzj0RQcdmzWLUF1dB5emdWmahurzEayqwl9URLC6uqOLJIRoJaaOLsChYNeaDwBfUMVuMXZUkYRolrihQ7H06I5/w0ac771H6iWXtNuxVY+HYEWFPlVWEqioIFhR2bAuvB5AsVpRrFYMFkt0WbFaMFj0ZS0URK1zo7rdqHV1qHV1hOrrIRCIHk9xOCh4522s3bu323sUQrQNCR80dDj1hxrChzcQkvAhDnmKopB60cWU/eMfVL32OikXXohibL3vrRYMEti+Hd/mzfi3bMG/eUt4vplgS4Z3d7sPriAmE1p9PWX33UfnF19EUZSD258QokNJ+KChw6kv5MNsVAiENB76dA0D85PpnZNAr6wE4qzyUYlDU9KE8VQ+9hiBbduo+/ZbEkaPPqD9hOrceFf8Sv3SpXhXrsK/eTP+4uImtQ+7Uux2zJmZmBpPGRnh5QxMGRkoRiOaz4fq86P5vOFlH5rPj+b3oXq9KCYzhrg4DPFxGOPiMMTH61NcHAaHg0BJCZtOP4P6HxdS+/kXJJ425kA/LiHEIUDOqDQ0u3hDXjqnOthY6eatJcW8taQ4uk2XNAe9sxPonZ1I7+wE+ndKIj/V0VFFFiLKYLeT/Ic/sPP55yl74AHqvvsOc35nLJ3zMeflY+mcjzExsclrNE0jsL0Ez9KleJYupX7ZUnxr1oK6e2drxWbD0qULloICLF27YC0owNK1K5auXTEkJrZLLYQlP5+0K65gxzPPUP7ww8QPPxGDQ/79CXG4UrRDbHhEl8tFUlISTqeTxF3+YLaVyvpKRr4zEoNi4KuzFjFv/Q7WlNXqU6mLito93z/j2IJULjq+C6f2zcZikr67ouMEysvZOOY0NK93j88bk5Iw5+tBRAuG8CxbtsdmE3NuLvZBg7APPAJL9+5YCwowZWejGDr++616vWw6/QwC27eT9serybz55o4ukhCikZacvyV8AC6/i2EzhwHwy4W/YDaamzy/s87H2rJaVofDyNryWlaWuAiFr4jJSLBy/uB8zj+2MzlJ9nYpsxC78m/Zgmf5cvxFxfiLiwgUb8NfXExox449v8Bkwta3L45BR+qBY9AgzFlZ7VvoFqr96iu2XX8DitlMt48+xNK1a0cXSQgRJuFjLzRNQw1pGHeppfCH/Bz9+tEALDh/AQmWhP3uq9TpYeaiImb+VExluGbEaFAY3SeTi47ryrAeadIpThwSVLcb/7btBIqL8BcVgxrCPnAgtv79MdgPr7CsaRrFV16F+4cfiBt+IvnPPSf/zoQ4REj42ANPrZ+vX11NfLKVk6f0bvKcpmkc+dqRqJrKN5O/IcOR0ez9+oMqX6wq47Uft7Joc1V0fbf0OC44tjN9cxPJSbKTnWiTq2eEaAW+zZvZNGEiBALkPfMMCSNHdHSRhBC07PwdMx1Od26vY+tvO0GD/D6pdD8qM/qcoihYjVY8QQ/e0J7bzPfGYjJwxhG5nHFELuvKa3l94VZm/bKdTTvc3PfJ6ibbJtpM5CTZyUqykZ1oJTvRRnaSnZ5Z8fTLTZJwIkQzWAsKSJs6lZ0vvED5Aw8QN/R4DDZbRxdLCNECMVPzAfDj7I388vlWrA4T5/5tMIlpDVXOw98cTrWvmtkTZtMjpcdBHafOF+T9pdv57LcySmo8lLm81Pv3fb8YgwI9sxIY0CmJI/KSOCJPv8zXapJAIsSuVLebjeNOJ1heTvoN15Nx3XUdXSQhYp40u+xFKKQy61+/ULHFRU73JM68ZRAGo97/45R3T6HMXcabp79Jv/R+rXpcTdNweYOUu7yUOb2UubyUO72UuryU1HhYVbLnK2rMRoVe2QkM6JTMcd1SGdUni3gZb0QIAFxz5rD9lj+jWK10++QTLHmdOrpIQsQ0aXbZC6PRwKmX9+Pt+xdTutHJT3O2cOz4bkDDKKctbXZpDkVRSLKbSbKb6Zm1586s5S4vy4trWLHdya/bnPy6rYbq+gC/bXfx23YXMxcXYTEZOKlnBuMGZDO6TxYJNvMe9yVELEgYOxbHW29Tv2gRFQ8/RN5TT3V0kYQQzRRT4QMgKcPOSVN68eX/VvHznC3k9UqhU8+UhlFOg3se06OtZSXaOLVfNqf2ywb02pJt1R5WbHeyrLiGr1aVs2mHmy9XlfPlqnIsRgPDe6YzbkAOo/pkkWSXICJii6IoZP/9b2w68yxqv/yKunk/EH/iCR1dLCFEM3T8yEEdoOfgbHoPzUHT4MsXV+GtCzQZ5fRQoCgK+akOxg3I4a/j+vD1n0/i05tO5IaRPeiWEYc/pPLV6gpueXs5x9z3JZe9/BPvLClmR13HhCchOoK1sJDUCy8EoPy++1D9/g4ukRCiOWKu5iPixHMLKdvopKa8nm9eW429QO986gsdmidvRVHok5NIn5xEbjmlJ+vK6/hkRSlzVpSyoaKOb9ZU8M2aChQFBuYlM7J3JiN7Z9Ivt32Gvxaio6Rffx3OTz7Bv3UrVa+8QvqVV3Z0kaI0TYNgEMXcsppJLRQiWFaGv0gfmyVQXESgtAzFZsWYmIQxMQFDYqK+nJSIMTERQ2Q5JeWQGJFWiH2JqQ6nu6osquXdaUtQgxqlg5byge1l/jn0n5xVeFabHre1rS+v5ZMVpXy1upzftruaPJeVaGVk70xG9MrkhMJ0HJaYzZvid6zm/fcp/b87UOx2ks6ciCkjo+kN7zIy2uykrHq9BLZvx18UHlV2WzGB4m0EthXjL96G5vVicDgwJCVhbDIlYkxKwpCUhGIyh/exlUBRMf7t2/d5Q799UcxmzLm5mPPywlMnLNHlPIzJyfKDRLQJudqlBZZ/XcwP76xHNYR4t/8j/HHkVM7vfX6bH7etlLu8fLumgq/XVDB/w44ml/haTAaGdE2lT04CPbP0qTArXgKJOOxpmsbWiy7Cs+TnvW9kMul33M3IwJiSHK41aDQlJ+m1CeHHmtdLqKaGUE0NwfA8VFOD6nRGHwdLy/Z4j5xWYTbroaFzPpb8zphzc9H8fkIuFyGXE9Xp0pdrXdFltbZ2v7s1OBxNg0mnTg2PO+VhjI9rm/cjfvckfLSApml88syvbF2xkyp7GXkXB7h00CVtftz24A2EWLS5KhxGyimu8uxxu7wUO72yEijMSqBnVjw9sxLonZ2AyShVt+LwodbX4/zkE4KlpQQqKghWVhKsqCRYUUGoqgra8E+dIS4Oc+fOeljIz8eSn6ffWTg/D0NiIqorHBRqnIRcTkJOJ6rTScjpIuR0ovm8em1FfmcsXTpjyc/Xb+hnbNk4P1owSLC8XB9Of9s2Atu34d+2jUD4cXOCkjEpKRxEOmHOycaUnYM5OwtTdjbmnBxMGRktLpeIDRI+WshT6+e/d32DwWNB6VvDtTee3S7HbU+aprGxso6Fm6pYX17LuvI61lfUsqNuzx30Em0mhvVIZ3jPDIb3zKBT8uF1DxAhGtMCAYI7dxIMh5JQjR4A9KlmtzAQcjpRbFZMyckYk5IxJCdhTE7WHzeaTBkZmDt3PmyaMlSfj8D2EgLbtxHYFg4m20v0oLJtG6Gamv3vxGjU33d2NubcHD10demKpWsXLF27HjafhWh9Ej4OwCPvP4Pts54oGBhzZX96HJ25/xf9DlS5/awrr40GknXltawqdVHrDTbZrltGHMMLMzipZwbHdkuVphohfodCdXUEtkdqTUoIlJURLCsjUFZGoKyUYHkFhPYzWnNiIpauXbF06RKe9HBmiIvHEBeHMT4OQ5w+7a0jrqZpaIEAWn09qteL6vGgeb1gNGJMSsaYkozBYmn2+9I0DbW2llBVFcGqKlS3Wy9LYiKGhESMSYkoVmurhibN7ydYWUmgogLN50exWjBYrfpxrFYUS6PHFgsoCprXi+r1Nrzveg+qp15fX+8BNYQpJwdLfj7GtJbdvFT1ePBv2YJ/82Z8mzdjsNlJu/yyVnu/IOHjgEz/eTor5pRz1PZTMNuMjLq4T5P7v8SSkKqxfFsN36+r5Pt1lSwrrkFt9C2xGA0c0zWFY7qm0j83kQF5SWQn2uTXjhC/c1ooRHDHToJlpQRKywiUlODfujU6BUtLW7Q/xWrFEK+HEkIh/cTr8aB6vaCq+36tw4GxUY2UIUlfVsxmQlXV0aARqqoiWF293w68itms7yMhAUNiAsaERL2jsN2O4rBjsDsw2GwYHHYUe+SxlVBtHcHycoKVFQTKy5s29bUhxeFo6BOUl9/QNyg7i0B5Bf7Nm/Vpy2Z8m7fs9v/G0qUL3T//rFXLJOHjADy7/Fn+88t/uHTrPzCXJQPQ94RcTphciNka2+2bTk+ABRt28P36Sr5ft4PtNbv3HUmPt9AvN4kBnZLo3ymR/p2S6JRsl0AiRAxRPR78RcX4t26JBpJAUTGh2lpUtxu1rg7V7UbztWBIA7MZg92OwWpFCwYJOZ37DSZ7Y4iLw5iaiiE+Xi+P00motvaA97c/itmMKTMTxW5D8wfQfD69FsPv12ty9nL6VSwWPfTY7fp7Dy+jQKCkhGBp2QH1YTImJ2MpKMBSUIC1Rw/SLrv0YN9iExI+DsDLv73Moz8/yoSCiZxRdSm/fL4VNEjOcnDq5f3I6LznYdFjjaZpbNrhZv6GHSwvdrKyxMn6ijpC6u5foxSHmV7ZCfTIjKdHRjw9MvXlrMTWrd4UQhxetEAA1e0mVOfWQ4C7DsVobDjZ2mz6stW6W9OMpqp6E0qjK5Cik9OJFghgTEnFmJqCKS0NY0oqprRUPXRYrbuXRdP0MkQ6Bbtc4eVavcnD4wk3f3hQvR60XZYNCQmYsvRLus2ZmZiysqKXeO+r/0tkDBjV50fz+yAUQrE7MNht++3Qq/r9evNYcTH+4mL98uxt2wgUFREoK8OUkaEHjIKu4bDRDUtBV0wpKQf+P60ZJHwcgJlrZvLAogc4pcspPHbyY2xbW81XL63CXePDYFQ4/qzuDByZj2KQk+auPP4Qa8pc/LbdyYrtTn7b7mJdeS3BPQQSgASriW7RQBJPQXocOUk2cpJtpMdZMchn3GLBkMpz32/CajJw8fFdsZjkSiUhRPuSG8sdgMiN5SIjnOb1SuG8vw/hm9dWs3n5Dua/u4HiVVWMvKQPcUm7p+dYZrcYGdQ5hUGdG1K1NxBiXbgT64YKfdpYWcfWnW5qfUGWF9ewvLhmt32ZDApZiTZykmxkJ+nznCQ7uck2CtLj6ZLmwGaO7WawXfmCIW54YylfrCoH4N2ft/GvSQMZkJfUwSUTQog9k/ARtqcby9nizYz94wBWzith/jvrKVpVxVv3LWbkxX3oOiC92fvWNI1gwE/Q5yPg8xH0h+c+H2ooSHaPnpittoMqv7euDr/XQ2J6xkHtp7XYzEaOyEvmiLzkJut9wRBbdtRHA8mGyjqKq+opc3qpqPUSVDW213j22K8EQFGgU7KdgvQ4umfE0y0jjoL0OLplxJOTaIu5WhO3L8jVr/3MDxt2YDEaiLMaWVNWy5nPzOeq4d24aVShhDUhxCEnpsLHttW/YbE7yOzabbfn9nZjOUVR6D+8E7k9kvnifyvZub2OT/79K31PzKVTz2TiU2zEJ1uJS7ZiNBlQ1RDFK1ewet5ctvz6C756N8H9dK5Kyspm4q1/J6Nz1wN6X1t+XconT0zDV+9m8PizOX7SBZhacBlae7KajPTKTqBX9u59aAIhlcpaH6VOL2VOL6VOjz53edlWVc+mHW5qvUG2VXvYVu1h3vodu+zbQHaSjawEG5mJVrISbWSF55kJDctx1t/H195ZH+DSlxfzS1ENDouRFy4+ht7ZCdz90So+Wl7Cs3M38vnKMqadcwTHdE3t6OIKIURUzPT52LLsZ2ZPuxdHcjJT7n+M+JSmf4znb5/PH7/6I71Te/PO+Hf2uI9gIMTC2ZtY/k3xbs+poUoMrCPgWUUosPchjo0mEyarFbPFislqxet24611YbJaOe2am+l1/InNfk+apvHTh+/xw8xX0bSG3tqpnfIZ88ebyO3Zu9n7OhxomsZOt59NlW42VdaxeYebjZVuNu2oo2hn/V77mOwqPd5Kz6x4CjPj6ZGVQGGmPqpratyhGdj2pLLWx0X/W8SaslqS7GZevnRwk2avL1aW8ff3f6Oi1oeiwCXHd+W2Mb1+N8FrV5qm8frCrXyyopSzB+Vx5qBO0u9FiHbWoR1OH3zwQWbNmsWaNWuw2+0MHTqUhx9+mF69ejXr9W0VPrx1dcy881aqSraR1a0Hf/jHQ5htDU0dS8qWcOnnl9I1sSsfnfXRPvdVvKqKNYtKqSmrYOe2pdRX/4oWavQrXLFiNPfCYOmFYkhEUUyYrDZScxNJ65RIWm4cqblxpObEYzB6mfPUI2z9dSkAgyecwwnnX4zBsO+qcr/Xw+fPPsG6hT8A0O/k0RQceQzfvPQf6p01KIqBo06fyLA/XIjZ8vvvoxIMqWyv8VDu8lHu8lLu8lJR22g5vN7t3/sASWlxFnpkxlOYFU/XtDhykuzkJNvITbKTkWDFeIg06Wyv8XDhfxexeYeb9Hgrr10+hD45u/9bcdYHuH/OKt5esg3Qh9F/+JwjGNaj+U2GhwNvIMRfZ61g1tLt0XW5STauGt6N84Z0lmYnIdpJh4aP0047jfPOO4/BgwcTDAb561//ym+//caqVauIi9v/DYva8mqXmrJSZvz9z3hrXfQYfDwTbrkjepfL33b8xvmfnE9OXA5fTPpin/vZtuo3fnzvDYpWrohea20wmcjrfRS5vY4lPq0n9bUqtTs8VJXWU13uRg3u+WO2Okz0PykHn2seSz6eBUCXIwZx+k1/wR6/58t7q8tK+OBf97FzWxEGo4kRU69i4CljURQFT10tc19+nlXzvgUgJSeXU/94E3m9+x3QZ/Z74/IG2FzpZn1FHevLa/V5Re1e73sT0bgjbE6yndwkG1mJNlLjLKTEWUh1WEiJM5MaZ8FuNrbZpcQbK+u46L+LKHF66ZRsZ8YVx9I1fd//rr5fV8kds1ZE+9GMG5BNv9wk8lLs5Kc6yE9xkB5vOSwvf95WXc8fX/+Z37a7MBoUJh2VxzdrK6is1Zs60+MtXH5CNy48rjMJtpbd1l4I0TKH1KW2lZWVZGZm8t133zF8+PD9bt/Wl9puW7OSd+/9G6FgkMETzmH4FH2QlQ3VGzjrw7NItaXy3R++2+vrV8/7ls+enY4aHmI4r09/+px4Mj2PPQFbfPweX6OGVJyVHnZud1NVUkdViZuqUjc15fXRcWK6D8ogv89OvvrvUwR9PpIys5jw57/t1j9l0y8/MeepR/DVu4lLTmH8LX+lU68+ux1z48+L+eqFp6mrrgJFYdBpZ3DieZc0qe3ZE03TCAWDmPYy7PHvVb0/yKZKtz7UfIXeCbbU6aW0xkN5rW+P45jsjdVk0EOJw0KS3YzJqGA2GjAaFMxGBaPBgNmgYDQomIwGrCYDXdIc0Zv77S0IrCxxcvH/FrPT7adbRhyvX34suc28506dL8i0z9bw6o9b9/i8zWwgL8VBfjiQdE510Cs7gd7ZiWQkHJo1Zws27uD6N5ZS5faTGmfh6fMHMbRHOt5AiHd+3sZ/5m6MBq5Em4mpQ7ty6bACUg6j5rW2UOr04PYFSYuzkmQ3x1wnbdF2DqnwsWHDBgoLC1mxYgX9+/ff7Xmfz4evUYdMl8tFfn5+m47zsXret8x5+lEATrnqBo4YNYbi2mLGzRqH3WRn8ZTFu70m0r9i3hsvA9Dz+BMZfsFUkjKzDrgcwUCIdYvL+e6NtaghjcyuiRw7PoEvnvsXzvIyTBYrY/54I72HnYSmqiyc9RYL3n0DNI3cnn0Yf8sdu/VdaczrruO71/7Hb99+CegdW0+68DKMZjPu6mrc1VXU1ehzd00V7ppq3DXVhIJBeh13AsMvvJTE9NgcYr6xkKpRUeulpEbvBFta46XE6aGi1kdNvZ8qd4Bqt58qtx9/6OBHSkyNs1CYGU+v7AR6ZumTLxji2hm/UOsN0i83kVcvG0JafMtDwdKiar5dW8m26nq2VXkorq6nzOXd52CJ6fEWemcn0js7gd45+rxHZnyHNWdomsaL87fwwJzVhFSNfrmJPHfR0eSlOJpsFwipfLishGfmbmBjpRsAh8XI+UM6c0ReEskOC8l2M8kOM8l2Cwk20+/yRFzq9LBw005+3LiThZuqKKqqjz5nMiikxllIi7eSHm8hPd5KWpyF9AQrqQ4LSQ4zSfamk8PSdjV74vB2yIQPVVWZMGECNTU1/PDDD3vc5u677+aee+7ZbX2bhI/S5ZDZD4wm5r89g4XvzcRgNHLOX/+JvVsuI98ZiUExsOyiZU3+calqiLmv/Jeln+l9QY4+4yxOmnJptMnmYJWsr2bOf1bgcweJT7VyytTu/PjuM2xZ/ot+vNPPpKa8lI1LFgEw8NTTGXHJFRhNzaud2LLsZ754/mlqd1a2qFwms4VjJpzNkAmT9ltjsiufJ8jahaUYTQZ6HpuN2bLnE5Wvvp5QwI8jKblF+z8UaZpGvT9EldtPdb0eRpyeACFVIxjSCKoaQVUNL6v645D+mk2V+k39tlbV7zMIHNMlhf9NHUySvfVqpvxBlZIa/Qqi4up6iqvq2bLTzZqyWjbvcO+xPEaDQrf0OPJTHeQm28hNtpObZNfnyXqTlNnY+h0+Pf4Qd8z6lfeXlQBw1qBOPHj2gH0GoZCq8cXKMp7+dgMrS1x73U5RINEWCSNmLCYDBkXBoOi1VIqiv+/IOoMCVrOReKuROIuJOKuJeKs+j7Mao8tmowF/UMUXDIXnkanhcUjVSHFYSIu3kBZn0QNBnJVEu6nFJ/pyl7dR2NjJlp31TZ43GhQcFuNuN49sLrNRIcluJjEcRhJt+nKizRSem0m0m6LrE2wm7GYjVpMBa2RuMmA1GTEblSbvzxsI4fQEopOr0bLTE0BVNaxmIzazEZvZgL3Rss1kjO4/8v9TQcFg0OeKAnq21I8XavLvUSMYUsPr9PUhFYwGMBsN4UnZbdlkNKAAGqCGa0c1DVRN09dpWvRxSNWi+29YVlFVCKoqiqLo3yWriTiL/l1yWI1YTfsZ7VTVot8nb0DFH1Sxmg3YLUYcZiOmNvh3uDeHTPi45ppr+PTTT/nhhx/Iy8vb4zbtVvNRXwX/6g7WBOg+Cq3HKcz5dhNrFi3EGhfHhLvu5vTvzgXglwt/wWzU/7gH/X4+ffpR1i2aD8DJF1/B0aef2XrlCqspr+fjfy/HWeHBbDMy5vK+FP02h8XvN1x5YzSbGX35tfQfcUqT12qaRvlmFwFfiNyeyRj38GXz1dfzw5uvsPHnxdjiE4hPTiEuJZW45FTiUlKID8/jklPx1Lr47vX/sW3VbwDEp6Yx/IKp9D7h5P3+IQz6Q6yYu52fP9+Cz63/cbPFmzliRB4DTs7DFqd/rnXVVSz5eDa/fvkpqhpi3PV/pudxJxzUZ9gaPHW1fP2/51BDIQqHHEvBoGOwxe25Oa1Nju8PsbGyjrVltayrqGVdmT5QW6nTw+g+WUw/78h2vaOwx68PFremzMXq0oa507Pvm3QZFMhMsEU77DYeMC6ynJlgbdEfxuIqvX/HyhK9f8ffxvXh0mFdm31y1jSNuesqmfXLdiprvTg9QZz1fmo8Aer30RG5I0VqJiLNeKCfNAOq2ijUNgRZXzBEuavppf0GBQZ0SuK47mkc1y2NwV1Tibea8AdVqtx+dtT52FHnY2edvrwzvC4SnhuHgECodU8XiqI3U1qMBrxB/cQpmjIblWggsVuM+IIhfAEVbyDUrM/MYjIQZzHisJhwWIw4rCYcZiP5qXamTRrYqmU9JMLH9ddfzwcffMD3339PQUFBs1/XZn0+ihbBzD+Apzq6KqgaeLvsOEqdRhLTUnhu0K/4LCoLzl9AgiUBb10d7//rXravWYnRZOK0626h99D991s5UN66AJ8+t4KS9TUoBoXhfyjEYt3CZ88+gS0+ngm3/JXs7oXR7Wsq6lm7qIx1i8pw7dDHJ7EnmOl1XA59huaQmrP/Dr57o2ka6xcv4LvXXsRVqY+cmdOzNyMvuYrsHj132z4UUlmzoJSfPtmCu0b/45eS7SAUVKNlM1mNdB9kJeBezNoF3xAKNvrlpSiMuuwajjx13AGX+WCVb9nMu/fdg7e24colxWAkv29/uh9zHD2OOZbEjI5phgqE1DapSTgQmqZR7vKxtryW7dUeSp36oHAlNZ5wPxlvs5qfDApkJFjJTrJHaxos0V/F+gnJEv6FbDAovPbjFqrrA6TGWfj3BUdxfPe0VntPvmAoepKtqdenQEhF1SCkaaiqFv31qoXXhcK/ON2+IG5fkLroPKSv8wep8wYJqCpWk/6L3NLoV3/jZUWBarefneHmuyq3nzrfgdVMKAr0z03iuG6pHN89jWO6ppLYCp1tIzV7zl1qI1yeALXeIC5vAJcnMg80eewLqvgCoWitz74YFJrUrDReNipK9KTrDYTwBsIn4mAo/Fg/GWvo/5809JoILVwToWla9A7dJoOCyahgMhgwGfXaLbPBEO6LpT8OqRqBkEYgpBII6bUk/l2W0cK1LJGaFkUfH0p/rC8bFDAZDRjDtWhGg4LJ0LAcOVa9PxT9Lu3vc9oTo0HBYjTgD9fi7EuPzHi+uuWkFh9jXzo0fGiaxg033MDs2bOZO3cuhYWF+39RI23a4VQNwbYlsP4LfSr7lfqgmRlbjsQVsFGe4uXzIeV8PfAWLIn9mfXsi+zcXozF7mDirX+nc/8jWrc8exAKqHw7Yw1rF5YBMHBUPsec3gmzxYzRZMbrDrBhSTlrF5VRtqmhCtlsNWKyGPDUNvwize6WSJ+hufQ4JhOL7cB+LQf9fn7+5H0WzX6bgE8PEf1OGsUJ511MfGoamqqx4ZcKFn24CWeF3rkvPtXKkDMK6HVsNgAbf6lk4QdL2LF1Lqp/DfqfBMgs6Mmwc89n48+L+PUr/dbOx51zPkMnX9Dk16wWrrrcV3u8pmm4KstJTM88oOawxR99xQ9v/BtNDaAYkjCYC1EDm9HUnU22y+hSEA0imQXd9/qr2+8NUrG1Fp87QJf+aZj20uz0e6SqGjvcPr1vTDiQlLm84cHj9MflLu8B/Yru3ymR5y46hk7N7Gh7OPMGQtEgstPtp6beD7DPzssmg0LX9LhWbZZrbZqmn7T1QKKHCF9QxWY2kGQ3E29teVPT71EgpFLvC1HnD0YDrjegYjEZsJn10GozG8LNTkZsJkO0JlHT9GDs8Ydw+4PheYh6X1APOP4gNrORMf2yW7XMHRo+rr32Wt544w0++OCDJmN7JCUlYbfv/w9Gu95YzlUKG75k58+f8sY3NfhVIxtz67g2bgPzN/ehLmgl3qpx9mk9yeh3HOQMhPRC2M8YHAdL0zR+/nQriz7cBEDXI9LpfVw26xaXs2XFDtTwH21Fgfy+qfQ6NpuCIzMwGBW2rtjJ6gWlbP1tJ1o4+ZosBnocnUmfobnk9EhCURQ0VcPvC+FzB/B5gvjrg/jqg/g8AQK+EBa7CVucGVu8GXu8mWCgjsWzX2fV998AYLbaSO/SG9cOI756KxjiscYlM+CkXhx5Sh8cSQkoikL5pg0smv026xcviL4/g6kLJtuxKKZOdDsyg+5HZ7D6+w/Y+NPHAKTmDSElbxxet4q31o/HHQANsrslkd8nhbw+qWR2SYyGkfJNG/jm5ecpWbuKjK7dOPG8i+l65NHN+gPmq/cz6+FnKVmjd8o1Wbsw4tKbSc/P4LfvtrP+p7UEvRsIBTaiBUuIBCeA+JRUOvcfSH6/I0jO7kWd00zZJhdlm5xUba+L9pWIS7YyZHwBvY/LxnCI1F50NFXVB4wrc+qdd+u8+i89fzCkn5gCavQEFekX0SnZxhUndpNxO4Q4RHVo+NjbH/yXXnqJqVOn7vf1HXVX2y1LF/POw/dg0BQURUPTFNIsbs7uvJJEc6M2VLMDsgfoQSTnSH2e0RuMrd8Ov/6ncr5+ZTWhXarf0vLi6X1cNoWDs/Z6kzu308fahWWsXlBKTXlDhzN7ghk1pOHzBBufR5vFYFAwmSvxOL8m4Nm+z21NFiuOpCRclRXRdYVDhjLkzMmgZPLL51vZvLzp8OhB33KC9d8AGgZzd8xx41CUPf+CszpMZBWYcO/8ju1rFrBrr8hOvftx4vmX0Kl3372Wcd3iIj5/9nH89esBSO9yApP+ehNxjX5V17v8rF5Qwm/fb6d2Rw1qYDOhwAa0UBGa6m+yP8WQhMHUGYO5MwZTPglpKWgaDc1QOXEcf2Y3uh6RHv13oqmqfmnzITocvhBCNNch0efjQHVU+AC47OEx9PtFP9l16tWHiVP/gN21HkqX6VfKlP4KAffuLzTZIKtfQxjJPRIy+oDp4E8oZZucfPrcCgB6Dsmm17HZpOc1vwOkpmmUbXSyekEp63+uIOhr2rHOaDZgdZiw2k363GHGZDES8Abx1AXw1gXwuANNXqdpGmqwGIUaMvIVEtJUvLXV1FXtpK66Cm9dw/DyisFAn2EnMeTMyaTldW5y7KpSN8u/Lqa61B2tYXFXr2b9wldRQ0HSO/dk1OW3kZiRjBrU2La2muLVVRSv3oGn5ieCnoWAHgCsCf0oOGoMnupfKV71HWpQb37qdtRghv3hoibjpbidPr56cQEbF7+EplaBYmTIhMs48YKJe/0cVVVj6287+e27bRStrELTgqjBEtRgEWqgGC1Uxq5pLj2/C5ndCqna7mLHtirUoA9N82MyhzCZQwQDXr0pS9OwxsWRlJFNUmYWiZlZJEWmjGwSMzNjYpRaIcThTcLHARo/ezzm33Zwfu5ZnHXRzbv/GlVDsHOjHkZKloUDyXLw7+FeLgYzZPaBlC6QmAeJuZDUCRLDU0I2GJvXLquqWrhD08G1g/q9QarL6rHYjFjCYcPUzCrsoD+E1x2IBhJffZDsbknEp+x+Ugz4fbirqqir3klSZjYJaS0bzrt41Qren3Yvfk896fldOPuv95CQmo6maWz65Sfmvvpfasr0Sy0tjlwU03AUY2709ZpaS9CzkJD/NyKBICl7IN2OGU9CahZLPv6O+uqPQPNhsSdx5u1/J7/P7gO17U1NRT2rfiihrtpHZpcEsrslkZhmpHTDKopXLqfot1+p3Lq5Re95f+JSUjn2zMkMOm18q+5XCCFai4SPAzTpw0msrV7Lc6OfY2inoc17kapC9eZdAsky8Dr3/TrFAPFZeihJzA2HksbzXEjIAVNs/uKt3LqZ9x64C3dNNQnpGYy67BqWff5xdOyTuOQUTrxgKn1PHEHAr1KyroaSDTW4Kj24dnpx7fDgqa0k6FmAGlgb3quCwdwVNaAHg4wuhZx9x537HKjtQNW7nBSvXMHObUWYbTYsNjsWhwMtZGLD0hqKVtaiaWYMBgs9jsnFbPXirq6kvqYST+1OvO6d+D1VBH01aKrebKMoZnoc/xfS8zNIznKQkuUgOcuBLd4sHfSEEB1OwscBmjJnCr9W/soTI55gZOeRB74jTYOarVC+EpzbwLUdnNvBVQKubXpHV3Xf4yREOdL1IJLSFdJ7hqdCfW5tv/EnOoKzooz3HriL6tKS6DqjycTRp5/JsWedi8Xu2MerwVcfwLXDS9HKNaz46l12blsZfa7/iFMYdfm1HTaMfHWZm4Xvb2LTsn0P/KZpGmhe/HXvoYUqMNqOw2xvGoytDhPJ4SCSkZ9AXu8UUnPjJJAIIdqVhI8DdPnnl7O4bDHThk9jbMHYtjuQqkL9joZg4ioNz0vC03aoLYWgd9/7SezUEEQiU0ZviM/UL4X5Hah3OZn98D2UbVhH92OO4+SLLic5O+eA9rVt9W8s/fwTugw4kgEjTz0kTs5lm5ysXViGooDZZsJiN2K26nOL1YQ5PN+2ejFzX5mO2RrHgFP/Tu3OIDXlHmqrvXvsOGxPMJPXK4W83qnk9U4hMf33f2mqEKJjteT83X5DJR4GrEa9icO7v5P+wTIY9IAQnwmdjtrzNpqmD4gWqTWp2gQ71jVM7spwYNkOm+Y2fa0tWQ8hmb31eUYvfZ6Qc9iFEkdiEuf/81/U7txxUPfRAf0mgHl9dr+/UEfK7pZEdrek/W6X0WUEyz5/i5qyUhJTNjHiQr1zbNAfoqbCQ015PTXlbko3OCnZUIOnNsD6JRWsX6JfbZSYbouGkfT8eP1ya61hOGg00NCiQUZVNUIBlVBAJRhQCQZC0eVQQCXoVwkFVRQDGAwGDEZll6lhncVqwhpn0i/fdpix2I1yybEQMU7CRyM2k37/El/It58t24GigCNVn7IH7P58fRXs3KAHkcq1DaGkajN4a6B4oT41Zk2E1G5gSwRLAlji9KYbS3iKLFsTws08hfpyBzMYjQcdPA53BoORwePP4csXnubnT97nyDHjMJr0K5PS8+KbXAEVCqqUb3aybU0129ZWU77JhWuHl1U7Slk1v7QD30UDs80YvsLKjNVhwmw1YjQbMJoMmMwGfbnxY5MBR6KFTr1SSEht2X2GhBCHHgkfjURqPg6J8LE/jlRwDIH8IU3XBzx6KKlcC5VroGK1vly1CXwuvTNsS8RnQ1oPSO8BaYXh5UJI7tzsq3VE6+g7fCQL3plB7c5K1sz/nn4njdrjdkaTgdzCFHILUxgyXr/KqXSDk21rqti2thpXpQfCwz8DEB4WOny/LX29omAyNwQBk1kfQbfxY6NJ0W+aFdJQQypqSCMU0lBDGpoafhzUCPjCA9jVBwmEL9kOeEMEvCHqqlv+by0p005+71Ty+qTQqWdK9H5BQojDh4SPRiI1H23e7NKWzHa9pmTX2pKgT79MuGYr+OrAH552W3brzT1Vm8BdAXVl+rR1l7sSG0yQ3EWvSUktCM/DU3LnmL1Kpy2ZLBaOGjeReW+8zOIP3qXviSOaNZS8xWaiS/80uvRvvXuhHKhQSMXvCeJzB/F5gvjq9cu2g/5GzTpBvWknFGxo5gkFVGoq6infUouzwoOzYju/fb8dRYGMLonk99ZHvs3ultjsy8cPN611yb0QhwIJH43YjOHwETqMw8femKyQ1VefmstTA1UbYccGvTZl5/rwfCME6vXnqjbu4YUKJOXroSQxF+wpu0zJYAvP7SlgS2rzIet/LwaeMo7F779D1fZiNv7yEz2OObaji9QiRqMBe7wFe/yBDcDn8wQpWVdN8Zpqtq2uorqsnootLiq2uPj5s60oBiU6YJ0tLjyPj9wmwKIvx5n1gfJCGpqqz1W1ofYmOqmR59VG24TXN9om+lhtvE81+lhRwGQxYrYZMVuM+n2YrPrcHF5vMCr43OGB/dz6WDq7zgO+ECg0rY0yGzBZws1TFv0x0FB2teE9RmqpNE3DZDbgSLLiSLLgSLQQl2jRHydaousah7jI/ZW0xvsNPzYYFQwGvX+PYlBaLRz5PUFqq7y4dnqp3emhdqcXDfTyhssel6jPrY6W3w8m8h0IBtSm4bdRCDaZDZhtRiw2vWnQbDPu8a7hjfcZCqj4vSECvhABXxC/NwSahtFkDP9/a2hSNJoNmEwGDCb9c1NDKqGgFg3f0QAeDuSqqkW/Q2ZbeG417vG9a5qG3xOk3uXHU+un3hVotOzHFmfi+LN6tPR/S6uR8NFIu3U4PVzYk6HT0frUmKpCbYnev6RqU8NUvVlf568DZ5E+NZc1UQ8htqSmy7bIcrI+Lkp8ZsPcnnLYdaA9WFaHg4GnjGXxB++y+P236X70kJj6JWy1mygYmEHBwAwA6qp9bFtTRfGaKratrtb/uIan3yUNgn69w6+PA7vrbYM9DI7YiNFsiIaNllwTqRj0MKIYFYzhQBIJWRabEXP4RG6xNiybrUa8dYFw2NCDhq+++e/PaDaEQ4kFi91MKKiiBhtO4Lue0CMn9ZbeYgL0Zs3oe7GaUENqOGiE8HtD0XtqtZSi7HaXiGa+kCaBxGQ24qsPUF/rRw3ufYdJGXYJH4cKq+kw6vPRkQwGSMrTp4ITmz6nafqVOJFAUlehN+NEJm9NeDk899fpr/O59MlZ3IJymHcJJBnh8JKkd5S1JujhJbIcWW9L1IfEP0xP2keNm8jPcz6gdP1atq9eSV7fQ+sKnvYUn2Kl9/E59D4+B03TcNf48br9DbcGqA3grfNHbxMQqUlQlD1cnRP+9R45ce5tfeSEqq83RH/xN/71H92vQe8XEzk5Bf16X5eAP/zYpy+Hgio2hxlr4xqbOHP05o62ODPWOJPej6bJVUchgkGVkL/hqiQFPQBEQ0CjMGBQFBSDXp56lx+3U/8VXO/0hR/rczV8sj4Qmqrpt3MPEo1HXpo5rtEubHFmEtJs+pRqQzEo1Dt9ernDZfXVBwkFVGp3eqndeeA/HE1mA0aLXhNhtBgxGhWCAZWAN4TfF4yeyENBlVCdirdu3+/JZDHol89bjSgGRf//FWxoRtz1nl27Bg9FYbeO14qiRL87AV9ID0+Nvl+42I3FZsSeqNdmORIs0eWO7rgt4aORSLOLhI+DoCgNlxF3Pm7/2wf9eiDxusDn1EeGjU6uhmVPlR5k6iqgrlx/jRoID9q2reXlNJgbalWsieGQkqjXsNgSw1cAxTVMZkejdeFlk01vzjKawWgFo0UPZm0sLjmF/iePZvmXn7L4g3diOnw0pigK8SnWPQ75L5pP0zR89UH8nuDuAcbQKNgoChhoaLoKNTTJNH4cCqr6CTPcyTjSFKHXFASjJ06rw0xio6CRkGbDYtv/KSrobxSknD783qDepNF4MisYTE2vnoo0gZjMxmizx76EgmpDmRuV32A0hGtBwmP02PRmtchdt/f1OatBLRpINFWLlstoUvZ7ObqmaQT9atPP0asHXKvDjD3RjCPBgslyaDZpS/hoRJpdOoDJ0hBWWiLoaxpG6sr1GhevE3y14ZqU2nCoafTYVwtoenCp36lPrclg0kNIJJAYTPrx9Aby8LIansLrFfT7/6R1g9TukNZdn6d20+8BtOsfRV8txwzpza9ffcbmZT9T+b9LyAhu0WuaTFb9nkKZ/fT+PZn99HFefuej4YrWoyhKtNalWYxAB15wZLIYSUy3t/lAepEg01pXVymKgtGsYDQb4ACKrihKtMnKkXj43RVbwkcjh9Q4H2LfTFZIztenllBV/UaA3nAzT3QermGJrPPXgb9enwfq9auAIlPkcaAe1F3apdWgPrW0ltnrhIqVu683x+khJKWL3lS1cwPUlZEM9EzozVpXBosXrub0TuH71/iAzZWw+fum+0np2hBIkiKfmdZohLHGc/R7DzlS9eH949L1uSO1TTsGBwMBPC4n9S7nbvN6p5O45GSOn3QBRpP82RLicCf/ihuJ1nz8Hq92ETqDoaEza2tQVb0WJeiDUABCPgj59eakkD98Dx+FcH11eNrlcSgANUX6lUM7NzbMncUQcEP5Cn1qLC6Dwf1SWPsjrK3NZNgpN5NcOEgf56ViFZSv0sNM+Sr9kunqLfq09pODeLOK3snXkRYOJGn6pd1GK5isaEYLnoABlwdqPSoud5BadwBfEEKagWBIIahqBEMQDKoEQyGCgQBBvx+f243fU7//EhgMDJswQa/lqivXa74aL/vr9P4/CTlNb9CYmCuXfwtxCJHw0Ui05iMoNR+imQwGMFgP/sSW2Xv3dUG/Pi7Lzo16cLCn6IO8pXUDewpZQBf3nWz9dSlL1jgZPayP/rpdh+x379BvclixWg8kteUNIQiloVmn8WM1pDdJuXfoc081IQ1qnfXU7gjhCjipDW7DFbDiCthwBazUBqwEtYOrGTEoGnZTCIdZxR6eHGYNFYXlpQ4WvTeTrkv+j06OfV+psUeOND2ExGfr/7+iIdC4SziMTHvayS4rFYPetGYwNswVY9N1mqo39/nd4Ro19+6Pg169D5HZHp4c4ceOhsdm2y5lVXYPsyj6vny1Tcfx2fWxGmT3ULzLvozm8LHj9LnFsctyeIqsbzy3xDVaZw+Xu/H3TWk4VmTZX9eoj1dNo75fjZZDgfBna9rlcw9PRlP48zc2mht2eRxeF/KFfzT4d5n7Gn48GM3hfl3WcB8viz43Whoea5peLjUQngcbPQ7qczWo/5vSQvoPFi3U6HFI/44oit7vzJrQMNL0rpPZru+zyY+c8A+fSNlDwYbPxWjW+7cZw83BkWWDWW+K3fVKxnYk4aOR3/U4H+LwY7KEbxxYuNdNhkyczNZfl7Ly2y8ZOul8HEnJu28Ulw7dTtKn/Qh4vZRtXEfl1s24/JXUBipxuSqp3VGJ21nTrGsB4+xGEh1GEh0GEmwaNkMAk+bDGPJiUj2YQvWYVDcmRcVkUDEpKhZDCIcpgNUQ3OtFSIH6nqxyZvFpSS8u6rUOa2Jaw1VO8VkQl6n/Qa0rD9+gsbTpTRqjfXxW7PkAQsSStB5ww88ddngJH41Ih1NxuMnvN4DsHj0p27COXz79iBPOu6jZr9U0DVdlOSXr1lCybjUl69ZQuXUzmrr3SyxNZgsJ6Rn6lJZOYnomiekZJGZkkpieSXxaOiZzMzrkqaGGX+Rel/6LTdtTx9yGDrojAxrbpv8X584qvk27hdOu/VNz32j4Jo0lehCpLdN/iWqhJvtvMqmhPe1o9/1qWvjXa7Dh160aath/pIah8T2ULHHhX7dxDY9NNj0gBb16X6KABwKNl+v15/ZU1safm6bqv9Sjv54b3a+p8WOjeQ/vfZfHIX/42G597q8Plyc8RR5H+0HV69v63Y2Ww9tE9r/XfkaaXq7o+D5JDeP7NH5stDT6rIMNn3Xj2oUmtQyNaxsa1ziEPyejpVHNhiV81Zq54blIU2rQr3/+ofA8UuMQ9IZrVszhWoZGtQ2RmpjIssGk15TurWam8b8JX93uHeUj/dCM5nC5LdEmz2gHd1O4dkMLNdS6NK6NiTQFh4L6SNQdSMJHI9LhVBxuFEVhyMRJfPjoAyz74mMGTzgHq8Ox23ZBvx/XjgpcFeVUFm2hZN0aStevwV1Tvdu28alpZHfvSVJWNomNQkZCegb2hMTWGdTMYGw4oTSz+40VGHdjOm/d/X+s/O5rCgYNptfxJ+z/hU1u0iiXJQtxKJDw0chhdWM5IcJ6HHMcKbl5VJdsY/5br5HeuQuuygqcFeU4K8txVVbgrq7a42sNRiOZXbuR27MPOT17k9uzD4npGe38DpqvU+++HHvWZBbOeosvX3iKnMJeh3R5hRB7JuGjkWifD2l2EYcRxWBg8ISz+eI/T7L0s4/2up3ZaiMpM4vk7FxyCnuR26sPWd16YLYcXleBHHfO+Wz5dSllG9bx2TOPM/nv9zXrBntCiEOHhI9GZHh1cbjqe+IINiz+kZryMpIys0jMyCIpI1OfZ2aRmJHZek0mHcxoMjHu+j/z6u03UrzyV5Z8PJvBE87p6GIJIVpAwkcjkWaXkBYioAYwGzpw2D4hWsBoMnPW7f/o6GK0m5ScToy45Eq+fP5pfnjzNToPOJKsgu4dXSwhRDNJXWUjdlPDGLcy1ocQh7YBI8fQ/ZjjUENB5jz1CAGfNJcKcbiQmo9GzAYzCgoaGh9t+gib0UZQCxJSQwTVYLRGJKSGMBvN9E3rS/+0/sRb5L4ZQrQ3RVE49eobeHXDWqq2F/P9jJcYddk1HV0sIUQzSPhoRFEU4sxx1AXqeGDRA817DQrdk7tzRMYRDEgfwBEZR9A9qTvGNrwHhhBC50hM4rRrbua9B//Bss8/oWDQMXQbNLijiwWA3+uhdscOfPV1GE1mDCYTxvCkL5vDkwkUBb+nHp+7Dp/bja++Hl99HV63G1+9Ozr8vMFoxGSxYDSbMZktGM0WTJbwZDZjNFuIT0klOTt3j5dcC3GoUDStGUMWtiOXy0VSUhJOp5PExMR2P/5ba97ii61fYDKYMCpGTAaTPikmjAZjdH1doI7fdvzG9rrtu+3DYXLQP70/fdP6YjVa0dDQNC06V1H1sXXCjxOtiWTYM0izp5FhzyDdnk6qLVUCjBDN9M3Lz7H004+wJybR/egh+gneaGp6wjeGl81m7PEJOJJScCQl4UhKxp6QiMHYvH9vaiiEz1OPv96Nu6Ya1w59BFjXjkpqd1ZGH3vrDmAI+FbkSEomOSuHlJxckrNySM7JJSU7V4KJaDMtOX9L+DhIOzw7WFG5gl93/MqKyhWs2LGC+uD+b5C1PwbFQIo1hQyHHkry4vMoTC6kMKWQHik9SLQc+p+NEO0l4Pcx444/sXNb0YHtQFGwJyTiSEwiLjkZe0ISmqri89Tjq3fjr6+PLgd9ze8PZnXEYYuPJxQKoQaDhIIBQsEgajCIGtp9FFWL3Y7VEY81Lg6rI65h7ojDYrejqSrBgJ+QP0Aw4CcYCBAK+An6/YQCAQI+H7U7K6l31uyzXCaLFZPZrNeiWCyYwjUo0ZoUsxmrI47EDP1KqaSMLBIzM0lIy2jeCLYiJkn46EAhNcQm5yZ+rfyV9TXrCakhDIoBRVFQUBrmKBgUAxoaTp+TSk8lOz07qfRUUuWtQtX2PsQ1QJYji8KUwoZAktyDgqSC6CitQsQaT10tq+fNJeD16Cf4UDB6om/8OOj3461z4a6pod7lxFPratY9a3ZlMluwJyaRmJFBQlpGdJj5hPQMEtP0Ieitjri9vl5VQ6jBEKFgEE1Vsdjtza592R9ffT01ZSXUlJdSXVpCTVkp1WUl1JSV7DeY7JOiEJ+c0hBKIpd1Z2aRlJlNQlq63owkYpKEj8NcSA1R7atmh2cHlfWV7PDsYLNrMxuqN7C+Zj1l7rK9vjbTnkmnhE7kxec1zOM7kZeQR6YjE4MiFzgJ0ZgaCuGpdVHvrKHe6aTeWU29y4XBaAjXODiwOhxYHHFY7Q4sDv2x0XR41gD46uvx1tUS9Pv12hO/P1p7oteq+An4/XjranFVVujD8ldW4Kws32+tj6IYSEhP12tKGo0xYzSbw2PMKOHt9P8oKPoqRcFqj8ORmIgjKRlbQgKGVmp2VtUQfo8Hv6der8GqrycUDOi1XCmp2OITDtnxbzRVRVVVtPCEotdaHarllfDxO1frr2VDzQbWV69nffV6fblmPU6fc5+vMxvM5MbnkhOXo0/xOdHl3LhcsuKysBgt7fQuRGsKqSHeXPsmRsXIhO4TcJilTV+0Lk3T8NS6cFWU46yswFVZjrOivNG8gmDA3zoHUxRs8Qk4EpOikz0xCZPFTCjYtEYr0pQVCgRQwzVbkT45Po+HgNezz0MZTSYcySnEJ6cSl5JCXHSegsFgRFX1m+JpmoqmRuaq3n9PVQn6fPi9nmjTnN9T3xB2wsuhYLA5n3CToLGnZjnQw4cjKfy5JCVjT0wiLikZR1IyjsQkbAmJBP2+cMdld7jTcl30sc/txueuIyE9o9XHBpLwEYM0TW++2Va3TZ9qt7G9bnt0XlpXSlDb9z8ABYV0e7oeRuJzyY3PpVN8JzrFd4qGFmnWOfRUe6v5y/d/YWHpQgBSrClc2PdCzut9Xsz1DQqEApiNh2eNxOFOU1Xczho9iFSURe8tVLtzB2owiBa5K7Cm/70CLXxDW/2E7quvp97l1DvqtsFpyWgyRWuvDEZjw7FiVFJWNlc8+d9W3aeED7GboBqkor5CDyLuUkrrSvW5u5SSuhLK3GV4Q/sfpCndnq6HkrhOJNuSiTfHk2BJIM4cR4IlYbfHSdakJoO3ida1aucq/vTtnyhxl2A32Um1pUavwIo3x3N+7/O5sO+FpNpSO7ikbWuHZwd3L7ibedvncXzO8UzsMZER+SMkLB+GIs1gHpeT+sjkdOJx1RAKBjGazRiNjS9X1q9gilzCbDJb9GayaBOZ3nS2p46ywUCA+ppq6qqrcNdU4a6uxl1TRV11NfXOajRNQzEYUML99gwGAxjCffgUBcVgwGy16sey27HaHZjDc0t0smNsZiddg8GgH89gwGAwNlrW55qqNTQRupzUO2v0z6nx47pazBZro07L8diadGDWOzTbExJbfVRgCR+ixTRNo8ZXQ4m7hNK6UrbXbaekroSSuhK2u7ezvXb7AV/F4zA5SLOnkWZL2+M82ZpMnDkOh9mBw+TAYXZgN9mlf8p+fLDhA+5deC++kI/OCZ2ZPmI6BUkFfLblM/634n9sqNkA6DdMnNRzEpf0u4TsuOwOLnXr+674O+5acBdV3qZ37k0wJ3Bq11M5s8eZDMwYeMi2kwvxeyHhQ7Q6TdNw+V1sq9sWDSVOn5O6QB3ugJtafy11gf9v795joyrzPoB/z1zOzPR+pRdLoa4Igmk3ojTVV3kjjawxLKjJkg3JkviHK5YsCJssbqLVZLPt6sasuASNbuQ/uZggwcTELpcxGq6lXS4qL7Cs8KaXkUvb6Vw6Z8757R/TczpDUaF0zvTy/SRPzjPPOT08/fUw53eec+aZQQzGBq1lUAsibtzKvc6b87l8yHJlWYlJjjsHOWpOYjk8wpL8OkfNQZYrCz534ud8Ll9iH+6sKfU9PZqu4S/H/oIdZ3cAABZXLcafH/1zyi0WQwwcuHwA7598H2eungEAuBwuLP/Zcvx63q9Rk18z6Z/vicQj+Ouxv2Ln/+0EAMwpnIPfL/w9TgROYO+FvegKdVnbzsqbhV/+7JdYdvcyVORUZKrLE8L16HVE4hEUegs5KknjiskHTQgigpAWwtXoVVyNXB29HK73D/UjrIURjifKT33MeCxcDpeVzBR5i1CWVYYZWTOsYr3OnoFc98R9+j0QDmDDwQ341/f/ggIFa36+Br+t/e0PjhKJCA51H8L7J9/H8d7jVrsCBWXZZYlPQuVUoSp3uAzXi73FEzYGQOJ20x+++AP+M/AfAMBv5v8Gv3vgd9aXQxpi4HjPcey5sAdt37UhEk88dKhAwYPlD6ImrwY5aiKBzVPzrGTWLDnuHKhOFQ7FMbpgpD6RYwQkEo2vr36NM1fPWMvkT8t5nV4UegtR4ClAobcwUTyJZa6aC9Whwu10J5YON9xON9wON1Snai2TJ2N0O9zWpIzWBI3DEzNO9FjRnWPyQZOWiCCqR0eSkeHlYGx4hEULIhRLLJNHWQa1RAlrYUTiEUTiEYTj4TGNvJjPTuSpecj35FvL5HqemmedpMxRmWx3NnwuX9reZE/0nsBG/0ZciVxBrjsXrY+14rGqx2755zsCHfjHqX/gaM9R62T8QzxOD0p9pSjNSsy4OyNrBkp8JVZbqS9R8j35tp5UdEPHtjPb8PfOvyNuxFHqK8Wf/udPeLjy4R/8mbAWxj8v/RN7zu/B0Z6j49ofl+KCx+WB1+mF1+WFx+mB1+WF1zlS9zg9idmRbzghJ792O9yJkbqkUTvz9qOZNHtdXhhiIKbHoBlaouhaSj2qR/Hv/n/jzJVEspE8+mNSoMDpcN7RqOTtUqBAdaojycxwPTmJcSgOmKcj8+HU5IdUgcRXYDgV50iSc2MZnonaEMOaVdoQY2SZNNP0jUmlU3GOakveh7kfkdR9Jv+8y+Gy6k7FCafDaSVeyada6/cb3r/VJiPrk2Nx4/ZWf0Sgiz6qzTymzPi6HC6rbrYXeArwi5pfjOvfmckH0TBN1xCOh61kJKyFcTVyFb3hXgTCAQTCAaveG+5FMHZnT78rUFJuE2W5sqwrR5dz+A1h+A04ua46VOsNwnqTNt88nG50DXZha+dWxCWOOYVz8Lf//Ruq86rH1EcRwbXotVGfijJf94Z7b3n0yaW4UOQtQpGvKLG8oRT7ipGn5qUkaNnubLgctz8RVfdgN/745R+tEZzG6kY0NzSjwFtwy/voGuyC///96Iv2YSA2YN0uDMaCI2U4sdXl5h91nGxm583GfcX3YUHxAswvno/7iu5DtjsbIS2E60PX0Rftw/Wh67gevY6+oT5ci15D31AfgrEgNF1DzEgkO2bSYyU/w+vML96MSxyaodma1NDYzc6bjb1P7x3XfTL5IBqjSDyCQDiA69HrGIgNoH+oHwOxAQwMDaA/1o+BoQGrPRgLIhQPIRQLIRQPpeV20Y2enP0kXnv4tbTO46HpGnrCPbgSuYJAOGBNdvd95PuRZeT7n5xX5sd4nV5ku7ORoyYSEq/Tm7hCG07QzKs1s+5UnPjs4mcIakH4XD68vOhlrLhnRVpHXW68ujSvdnXRrTZN1zCkDyESj2BIH0qpR+NRRPUoYnoscXI2iySWuqFbJ2vN0KwEORKPIKIl1eMRhLUwonoUTsUJ1ammxObGK9q7cu7CguIFWFCyAPOK5iFXzU1bjG7GHBkwf8+4EUdMjyFmxBLLpCTGbNN0zbq6tyYeG64r1sRkCnTRU2N5Q0w1Q7NGI8xZpM26oihWHUDKaIH5900uuujWbTYosG63mbNUm/syjwnd0BPL4boZA90YSWLN49Xsw83azb4mx8KKQdLvZPbFHLFJ7lNc4taoWPJIWXK91FeKl+tfHte/PZMPIpuZt4tCWgghLWTdAgpr4VH/6Ue91kfeiK11w1eVZrshBpbOWopfzf3VhLl3HtNjuBa9lloiieXVaOJ5nmuRa9ZDyYOxQcSMO5uEqrakFi2Ptox51GcyE5EJ87cnupnbOX9zEn6icaAoinV/vsRXkunu2EJ1qijPLr+tj+9qumYlZ8mJ2pA+ZF2pmVewZjFfl2WVYfk9y6fUJ5duBxMPmkqYfBCRbdxONwqcBbf1nAYRTT2cxYmIiIhsxeSDiIiIbMXkg4iIiGzF5IOIiIhsxeSDiIiIbMXkg4iIiGzF5IOIiIhsxeSDiIiIbMXkg4iIiGzF5IOIiIhsxeSDiIiIbMXkg4iIiGzF5IOIiIhsNeG+1VZEAAADAwMZ7gkRERHdKvO8bZ7Hf8yESz6CwSAAYObMmRnuCREREd2uYDCI/Pz8H91GkVtJUWxkGAa6urqQm5sLRVHGdd8DAwOYOXMmLl++jLy8vHHdN43GeNuL8bYX420vxtteY4m3iCAYDKKyshIOx48/1THhRj4cDgeqqqrS+m/k5eXx4LUR420vxttejLe9GG973W68f2rEw8QHTomIiMhWTD6IiIjIVtMq+fB4PGhubobH48l0V6YFxttejLe9GG97Md72Sne8J9wDp0RERDS1TauRDyIiIso8Jh9ERERkKyYfREREZCsmH0RERGSraZN8bNmyBbNnz4bX60V9fT2OHj2a6S5NGV988QWWLVuGyspKKIqCTz75JGW9iODVV19FRUUFfD4fGhsbce7cucx0dpJraWnBQw89hNzcXMyYMQMrVqzA2bNnU7aJRqNoampCcXExcnJy8Oyzz6K3tzdDPZ7ctm7ditraWmuipYaGBnz22WfWesY6vVpbW6EoCtavX2+1Mebj57XXXoOiKCll3rx51vp0xnpaJB87duzAhg0b0NzcjBMnTqCurg5Lly5FIBDIdNemhFAohLq6OmzZsuWm69944w1s3rwZ7777Lo4cOYLs7GwsXboU0WjU5p5Ofn6/H01NTTh8+DDa2tqgaRqeeOIJhEIha5uXXnoJe/fuxa5du+D3+9HV1YVnnnkmg72evKqqqtDa2or29nYcP34cjz/+OJYvX44zZ84AYKzT6dixY3jvvfdQW1ub0s6Yj68FCxagu7vbKl9++aW1Lq2xlmlg0aJF0tTUZL3WdV0qKyulpaUlg72amgDI7t27rdeGYUh5ebm8+eabVltfX594PB756KOPMtDDqSUQCAgA8fv9IpKIrdvtll27dlnbfPPNNwJADh06lKluTimFhYXywQcfMNZpFAwGZc6cOdLW1iaLFy+WdevWiQiP7/HW3NwsdXV1N12X7lhP+ZGPWCyG9vZ2NDY2Wm0OhwONjY04dOhQBns2PVy8eBE9PT0p8c/Pz0d9fT3jPw76+/sBAEVFRQCA9vZ2aJqWEu958+ahurqa8b5Duq5j+/btCIVCaGhoYKzTqKmpCU899VRKbAEe3+lw7tw5VFZW4u6778aqVatw6dIlAOmP9YT7YrnxduXKFei6jrKyspT2srIyfPvttxnq1fTR09MDADeNv7mOxsYwDKxfvx6PPPII7r//fgCJeKuqioKCgpRtGe+xO3XqFBoaGhCNRpGTk4Pdu3dj/vz56OzsZKzTYPv27Thx4gSOHTs2ah2P7/FVX1+Pbdu2Ye7cueju7sbrr7+ORx99FKdPn057rKd88kE0VTU1NeH06dMp92hp/M2dOxednZ3o7+/Hxx9/jNWrV8Pv92e6W1PS5cuXsW7dOrS1tcHr9Wa6O1Pek08+adVra2tRX1+PWbNmYefOnfD5fGn9t6f8bZeSkhI4nc5RT+j29vaivLw8Q72aPswYM/7ja+3atfj0009x4MABVFVVWe3l5eWIxWLo6+tL2Z7xHjtVVXHPPfdg4cKFaGlpQV1dHd5++23GOg3a29sRCATwwAMPwOVyweVywe/3Y/PmzXC5XCgrK2PM06igoAD33nsvzp8/n/bje8onH6qqYuHChdi3b5/VZhgG9u3bh4aGhgz2bHqoqalBeXl5SvwHBgZw5MgRxn8MRARr167F7t27sX//ftTU1KSsX7hwIdxud0q8z549i0uXLjHe48QwDAwNDTHWabBkyRKcOnUKnZ2dVnnwwQexatUqq86Yp8/g4CAuXLiAioqK9B/fd/zI6iSwfft28Xg8sm3bNvn666/l+eefl4KCAunp6cl016aEYDAoHR0d0tHRIQDkrbfeko6ODvnuu+9ERKS1tVUKCgpkz549cvLkSVm+fLnU1NRIJBLJcM8nnzVr1kh+fr4cPHhQuru7rRIOh61tXnjhBamurpb9+/fL8ePHpaGhQRoaGjLY68lr06ZN4vf75eLFi3Ly5EnZtGmTKIoin3/+uYgw1nZI/rSLCGM+njZu3CgHDx6UixcvyldffSWNjY1SUlIigUBARNIb62mRfIiIvPPOO1JdXS2qqsqiRYvk8OHDme7SlHHgwAEBMKqsXr1aRBIft33llVekrKxMPB6PLFmyRM6ePZvZTk9SN4szAPnwww+tbSKRiLz44otSWFgoWVlZ8vTTT0t3d3fmOj2JPffcczJr1ixRVVVKS0tlyZIlVuIhwljb4cbkgzEfPytXrpSKigpRVVXuuusuWblypZw/f95an85YKyIidz5+QkRERHRrpvwzH0RERDSxMPkgIiIiWzH5ICIiIlsx+SAiIiJbMfkgIiIiWzH5ICIiIlsx+SAiIiJbMfkgIiIiWzH5ICIiIlsx+SAiIiJbMfkgIiIiWzH5ICIiIlv9F6MBNx+GFu8pAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='Loss')\n",
    "plt.plot(history.history['box_loss'], label='box_loss')\n",
    "plt.plot(history.history['class_loss'], label='class_loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.plot(history.history['val_box_loss'], label='val_box_loss')\n",
    "plt.plot(history.history['val_class_loss'], label='val_class_loss')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "pd.DataFrame.from_dict(history.history).to_csv('model-s-onlyhead-test2-history' + now.strftime(\"-%m%d%Y-%H%M%S\") + '.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "23e4a255f1664c699d2d6cf00253559c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b618213856a34ec3830ad0b48a5a0028",
      "placeholder": "",
      "style": "IPY_MODEL_8c4cd4fca7d349d5b5d0eb212d5d84f2",
      "value": " 4660/4660 [00:03&lt;00:00, 1138.91it/s]"
     }
    },
    "2b949297991243388c2bbd0a04760f41": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a1c6cbfd5c614a68ba9a3bb1f5efc5f7",
       "IPY_MODEL_611f30558a3d4278bb6cdeb52c98cff5",
       "IPY_MODEL_23e4a255f1664c699d2d6cf00253559c"
      ],
      "layout": "IPY_MODEL_6fc913a8f1604a639b5a45437af4718c"
     }
    },
    "5dc5446c9611411ca61b12b715253919": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "611f30558a3d4278bb6cdeb52c98cff5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5dc5446c9611411ca61b12b715253919",
      "max": 4660,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_66722e0666bf4bfa96238cdec21491f6",
      "value": 4660
     }
    },
    "66722e0666bf4bfa96238cdec21491f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "66b3cacb326448829fc378be51cbeebe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6fc913a8f1604a639b5a45437af4718c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8c4cd4fca7d349d5b5d0eb212d5d84f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a1c6cbfd5c614a68ba9a3bb1f5efc5f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e3c791bfcf6c453d85dae4f359b74f83",
      "placeholder": "",
      "style": "IPY_MODEL_66b3cacb326448829fc378be51cbeebe",
      "value": "100%"
     }
    },
    "b618213856a34ec3830ad0b48a5a0028": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e3c791bfcf6c453d85dae4f359b74f83": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
